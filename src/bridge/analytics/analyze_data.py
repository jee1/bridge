"""í†µí•© ë°ì´í„° ë¶„ì„ í•¨ìˆ˜.

Bridge Analyticsì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Union

import pandas as pd
import pyarrow as pa

from bridge.analytics.core.data_integration import UnifiedDataFrame
from bridge.analytics.core.integrated_data_layer import IntegratedDataLayer
from bridge.analytics.core.statistics import StatisticsAnalyzer
from bridge.analytics.core.visualization import ChartGenerator, DashboardGenerator, ReportGenerator
from bridge.analytics.quality.comprehensive_metrics import ComprehensiveQualityMetrics

logger = logging.getLogger(__name__)


@dataclass
class AnalysisConfig:
    """ë¶„ì„ ì„¤ì •ì„ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""

    # ë°ì´í„° í†µí•© ì„¤ì •
    enable_data_integration: bool = True
    auto_schema_mapping: bool = True
    merge_strategy: str = "union"
    enable_streaming: bool = True

    # ë¶„ì„ ì„¤ì •
    include_descriptive_stats: bool = True
    include_correlation_analysis: bool = True
    include_distribution_analysis: bool = True
    include_quality_metrics: bool = True

    # ì‹œê°í™” ì„¤ì •
    generate_charts: bool = True
    generate_dashboard: bool = True
    generate_report: bool = True
    chart_columns: Optional[List[str]] = None

    # í’ˆì§ˆ ê²€ì¦ ì„¤ì •
    quality_threshold: float = 0.8
    include_outlier_detection: bool = True

    # ì¶œë ¥ ì„¤ì •
    verbose: bool = True
    save_charts: bool = False
    output_dir: Optional[str] = None


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""

    # ê¸°ë³¸ ì •ë³´
    success: bool
    data_summary: Dict[str, Any]
    analysis_time: float

    # í†µê³„ ë¶„ì„ ê²°ê³¼
    descriptive_stats: Optional[Dict[str, Any]] = None
    correlation_analysis: Optional[Dict[str, Any]] = None
    distribution_analysis: Optional[Dict[str, Any]] = None

    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    quality_metrics: Optional[Dict[str, Any]] = None

    # ì‹œê°í™”
    charts: Optional[Dict[str, Any]] = None
    dashboard: Optional[Any] = None
    report: Optional[Dict[str, Any]] = None

    # ì˜¤ë¥˜ ì •ë³´
    errors: Optional[List[str]] = None
    warnings: Optional[List[str]] = None


def analyze_data(
    data: Union[
        pd.DataFrame,
        pa.Table,
        List[Dict[str, Any]],
        Dict[str, Any],
        UnifiedDataFrame,
        Dict[str, Union[pd.DataFrame, pa.Table, List[Dict[str, Any]]]],
    ],
    config: Optional[AnalysisConfig] = None,
    **kwargs
) -> AnalysisResult:
    """í†µí•© ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” Bridge Analyticsì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬
    ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        data: ë¶„ì„í•  ë°ì´í„°
            - pandas DataFrame
            - Arrow Table
            - ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            - ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬
            - UnifiedDataFrame
            - ë‹¤ì¤‘ ì†ŒìŠ¤ ë”•ì…”ë„ˆë¦¬ {ì†ŒìŠ¤ëª…: ë°ì´í„°}
        config: ë¶„ì„ ì„¤ì • (ì„ íƒì‚¬í•­)
        **kwargs: ì¶”ê°€ ì„¤ì • (configë¥¼ ë®ì–´ì”€)

    Returns:
        AnalysisResult: ì¢…í•© ë¶„ì„ ê²°ê³¼

    Examples:
        >>> import pandas as pd
        >>> from bridge.analytics.analyze_data import analyze_data
        >>>
        >>> # ë‹¨ì¼ ë°ì´í„°í”„ë ˆì„ ë¶„ì„
        >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
        >>> result = analyze_data(df)
        >>>
        >>> # ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° ë¶„ì„
        >>> data_sources = {
        ...     'sales': sales_df,
        ...     'customers': customers_df
        ... }
        >>> result = analyze_data(data_sources)
        >>>
        >>> # ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ë¶„ì„
        >>> config = AnalysisConfig(
        ...     include_quality_metrics=True,
        ...     generate_charts=True,
        ...     quality_threshold=0.9
        ... )
        >>> result = analyze_data(df, config)
    """
    import time

    start_time = time.time()
    errors = []
    warnings = []

    # ì„¤ì • ì´ˆê¸°í™”
    if config is None:
        config = AnalysisConfig()

    # kwargsë¡œ ì„¤ì • ë®ì–´ì“°ê¸°
    for key, value in kwargs.items():
        if hasattr(config, key):
            setattr(config, key, value)

    try:
        logger.info("ë°ì´í„° ë¶„ì„ ì‹œì‘")

        # 1. ë°ì´í„° í†µí•©
        unified_data = _integrate_data(data, config, errors, warnings)

        # 2. ë°ì´í„° ìš”ì•½
        data_summary = _get_data_summary(unified_data)

        # 3. í†µê³„ ë¶„ì„
        descriptive_stats = None
        correlation_analysis = None
        distribution_analysis = None

        if config.include_descriptive_stats or config.include_correlation_analysis or config.include_distribution_analysis:
            stats_analyzer = StatisticsAnalyzer()
            
            if config.include_descriptive_stats:
                try:
                    descriptive_stats = stats_analyzer.generate_summary_report(
                        unified_data, config.chart_columns
                    )
                except Exception as e:
                    error_msg = f"ê¸°ìˆ  í†µê³„ ë¶„ì„ ì‹¤íŒ¨: {e}"
                    errors.append(error_msg)
                    logger.error(error_msg)

            if config.include_correlation_analysis:
                try:
                    corr_result = stats_analyzer.calculate_correlation(
                        unified_data, config.chart_columns
                    )
                    correlation_analysis = {
                        "correlation_matrix": corr_result.correlation_matrix.to_dict(),
                        "strong_correlations": corr_result.strong_correlations,
                        "moderate_correlations": corr_result.moderate_correlations,
                    }
                except Exception as e:
                    error_msg = f"ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}"
                    errors.append(error_msg)
                    logger.error(error_msg)

            if config.include_distribution_analysis:
                try:
                    distribution_analysis = stats_analyzer.calculate_distribution_stats(
                        unified_data, config.chart_columns
                    )
                except Exception as e:
                    error_msg = f"ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}"
                    errors.append(error_msg)
                    logger.error(error_msg)

        # 4. í’ˆì§ˆ ë©”íŠ¸ë¦­
        quality_metrics = None
        if config.include_quality_metrics:
            try:
                quality_analyzer = ComprehensiveQualityMetrics()
                quality_result = quality_analyzer.calculate_overall_quality(unified_data)
                quality_metrics = {
                    "overall_score": quality_result.overall_score,
                    "completeness": quality_result.completeness,
                    "accuracy": quality_result.accuracy,
                    "consistency": quality_result.consistency,
                    "validity": quality_result.validity,
                    "missing_ratio": quality_result.missing_ratio,
                    "duplicate_ratio": quality_result.duplicate_ratio,
                    "constraint_violations": quality_result.constraint_violations,
                    "data_type_consistency": quality_result.data_type_consistency,
                }
                
                # í’ˆì§ˆ ê²½ê³ 
                if quality_result.overall_score < config.quality_threshold:
                    warnings.append(f"ë°ì´í„° í’ˆì§ˆì´ ì„ê³„ê°’({config.quality_threshold}) ë¯¸ë§Œì…ë‹ˆë‹¤: {quality_result.overall_score:.3f}")
                    
            except Exception as e:
                error_msg = f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}"
                errors.append(error_msg)
                logger.error(error_msg)

        # 5. ì‹œê°í™”
        charts = None
        dashboard = None
        report = None

        if config.generate_charts or config.generate_dashboard or config.generate_report:
            try:
                chart_generator = ChartGenerator()
                dashboard_generator = DashboardGenerator()
                report_generator = ReportGenerator()

                if config.generate_charts:
                    charts = _generate_charts(unified_data, chart_generator, config)

                if config.generate_dashboard:
                    dashboard = dashboard_generator.create_analytics_dashboard(unified_data)

                if config.generate_report:
                    report = report_generator.generate_analytics_report(unified_data)

            except Exception as e:
                error_msg = f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}"
                errors.append(error_msg)
                logger.error(error_msg)

        # 6. ê²°ê³¼ ìƒì„±
        analysis_time = time.time() - start_time

        result = AnalysisResult(
            success=len(errors) == 0,
            data_summary=data_summary,
            analysis_time=analysis_time,
            descriptive_stats=descriptive_stats,
            correlation_analysis=correlation_analysis,
            distribution_analysis=distribution_analysis,
            quality_metrics=quality_metrics,
            charts=charts,
            dashboard=dashboard,
            report=report,
            errors=errors if errors else None,
            warnings=warnings if warnings else None,
        )

        if config.verbose:
            _print_analysis_summary(result)

        logger.info(f"ë°ì´í„° ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {analysis_time:.2f}ì´ˆ)")
        return result

    except Exception as e:
        error_msg = f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        errors.append(error_msg)
        logger.error(error_msg)

        return AnalysisResult(
            success=False,
            data_summary={},
            analysis_time=time.time() - start_time,
            errors=errors,
        )


def _integrate_data(
    data: Union[
        pd.DataFrame,
        pa.Table,
        List[Dict[str, Any]],
        Dict[str, Any],
        UnifiedDataFrame,
        Dict[str, Union[pd.DataFrame, pa.Table, List[Dict[str, Any]]]],
    ],
    config: AnalysisConfig,
    errors: List[str],
    warnings: List[str],
) -> UnifiedDataFrame:
    """ë°ì´í„°ë¥¼ í†µí•©í•©ë‹ˆë‹¤."""
    try:
        # ì´ë¯¸ UnifiedDataFrameì¸ ê²½ìš°
        if isinstance(data, UnifiedDataFrame):
            return data

        # ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„°ì¸ ê²½ìš°
        if isinstance(data, dict) and not _is_single_data_dict(data):
            if config.enable_data_integration:
                integrated_layer = IntegratedDataLayer(
                    auto_schema_mapping=config.auto_schema_mapping
                )
                return integrated_layer.integrate_data_sources(
                    data,
                    merge_strategy=config.merge_strategy,
                    enable_streaming=config.enable_streaming,
                )
            else:
                warnings.append("ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„°ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ ë°ì´í„° í†µí•©ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        # ë‹¨ì¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ UnifiedDataFrameìœ¼ë¡œ ë³€í™˜
        return UnifiedDataFrame(data)

    except Exception as e:
        error_msg = f"ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}"
        errors.append(error_msg)
        raise


def _is_single_data_dict(data: Dict[str, Any]) -> bool:
    """ë”•ì…”ë„ˆë¦¬ê°€ ë‹¨ì¼ ë°ì´í„°ì¸ì§€ ë‹¤ì¤‘ ì†ŒìŠ¤ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    if not data:
        return True
    
    # ì²« ë²ˆì§¸ ê°’ì´ ë°ì´í„° êµ¬ì¡°ì¸ì§€ í™•ì¸
    first_value = next(iter(data.values()))
    # DataFrameì´ë‚˜ Tableì´ë©´ ë‹¤ì¤‘ ì†ŒìŠ¤, ê·¸ ì™¸ì—ëŠ” ë‹¨ì¼ ë°ì´í„°
    return not isinstance(first_value, (pd.DataFrame, pa.Table))


def _get_data_summary(unified_data: UnifiedDataFrame) -> Dict[str, Any]:
    """ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        pandas_df = unified_data.to_pandas()
        
        return {
            "total_rows": int(len(pandas_df)),
            "total_columns": int(len(pandas_df.columns)),
            "column_names": list(pandas_df.columns),
            "column_types": {
                col: str(dtype) for col, dtype in pandas_df.dtypes.items()
            },
            "numeric_columns": int(len(pandas_df.select_dtypes(include=["number"]).columns)),
            "categorical_columns": int(len(pandas_df.select_dtypes(include=["object"]).columns)),
            "missing_values": int(pandas_df.isnull().sum().sum()),
            "duplicate_rows": int(pandas_df.duplicated().sum()),
            "memory_usage_mb": round(float(pandas_df.memory_usage(deep=True).sum()) / 1024 / 1024, 2),
        }
    except Exception as e:
        logger.error(f"ë°ì´í„° ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


def _generate_charts(
    unified_data: UnifiedDataFrame, 
    chart_generator: ChartGenerator, 
    config: AnalysisConfig
) -> Dict[str, Any]:
    """ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        pandas_df = unified_data.to_pandas()
        charts = {}

        # ìˆ«ìí˜• ì»¬ëŸ¼ ì„ íƒ
        numeric_columns = pandas_df.select_dtypes(include=["number"]).columns.tolist()
        categorical_columns = pandas_df.select_dtypes(include=["object"]).columns.tolist()

        # ë¶„ì„í•  ì»¬ëŸ¼ ê²°ì •
        target_columns = config.chart_columns or numeric_columns

        # íˆìŠ¤í† ê·¸ë¨ (ì²« ë²ˆì§¸ ìˆ«ìí˜• ì»¬ëŸ¼)
        if numeric_columns:
            charts["histogram"] = chart_generator.create_histogram(
                unified_data, numeric_columns[0]
            )

        # ë§‰ëŒ€ ì°¨íŠ¸ (ì²« ë²ˆì§¸ ë²”ì£¼í˜• ì»¬ëŸ¼)
        if categorical_columns:
            charts["bar_chart"] = chart_generator.create_bar_chart(
                unified_data, categorical_columns[0]
            )

        # ì‚°ì ë„ (ë‘ ê°œì˜ ìˆ«ìí˜• ì»¬ëŸ¼)
        if len(numeric_columns) >= 2:
            charts["scatter_plot"] = chart_generator.create_scatter_plot(
                unified_data, numeric_columns[0], numeric_columns[1]
            )

        # ë°•ìŠ¤ í”Œë¡¯
        if numeric_columns:
            charts["box_plot"] = chart_generator.create_box_plot(
                unified_data, None, numeric_columns[0]
            )

        # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        if len(numeric_columns) >= 2:
            charts["heatmap"] = chart_generator.create_heatmap(
                unified_data, columns=numeric_columns
            )

        return charts

    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


def _print_analysis_summary(result: AnalysisResult) -> None:
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n" + "="*60)
    print("ğŸ“Š Bridge Analytics - ë°ì´í„° ë¶„ì„ ê²°ê³¼")
    print("="*60)
    
    # ê¸°ë³¸ ì •ë³´
    print(f"âœ… ë¶„ì„ ì„±ê³µ: {'ì˜ˆ' if result.success else 'ì•„ë‹ˆì˜¤'}")
    print(f"â±ï¸  ë¶„ì„ ì‹œê°„: {result.analysis_time:.2f}ì´ˆ")
    
    # ë°ì´í„° ìš”ì•½
    if result.data_summary:
        print(f"\nğŸ“‹ ë°ì´í„° ìš”ì•½:")
        print(f"   â€¢ ì´ í–‰ ìˆ˜: {result.data_summary.get('total_rows', 0):,}")
        print(f"   â€¢ ì´ ì—´ ìˆ˜: {result.data_summary.get('total_columns', 0)}")
        print(f"   â€¢ ìˆ«ìí˜• ì»¬ëŸ¼: {result.data_summary.get('numeric_columns', 0)}")
        print(f"   â€¢ ë²”ì£¼í˜• ì»¬ëŸ¼: {result.data_summary.get('categorical_columns', 0)}")
        print(f"   â€¢ ê²°ì¸¡ê°’: {result.data_summary.get('missing_values', 0):,}")
        print(f"   â€¢ ì¤‘ë³µ í–‰: {result.data_summary.get('duplicate_rows', 0):,}")
        print(f"   â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {result.data_summary.get('memory_usage_mb', 0)} MB")
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    if result.quality_metrics:
        print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ:")
        print(f"   â€¢ ì „ì²´ ì ìˆ˜: {result.quality_metrics.get('overall_score', 0):.3f}")
        print(f"   â€¢ ì™„ì „ì„±: {result.quality_metrics.get('completeness', 0):.3f}")
        print(f"   â€¢ ì •í™•ì„±: {result.quality_metrics.get('accuracy', 0):.3f}")
        print(f"   â€¢ ì¼ê´€ì„±: {result.quality_metrics.get('consistency', 0):.3f}")
        print(f"   â€¢ ìœ íš¨ì„±: {result.quality_metrics.get('validity', 0):.3f}")
    
    # ê²½ê³  ë° ì˜¤ë¥˜
    if result.warnings:
        print(f"\nâš ï¸  ê²½ê³  ({len(result.warnings)}ê°œ):")
        for warning in result.warnings:
            print(f"   â€¢ {warning}")
    
    if result.errors:
        print(f"\nâŒ ì˜¤ë¥˜ ({len(result.errors)}ê°œ):")
        for error in result.errors:
            print(f"   â€¢ {error}")
    
    print("="*60)


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_analysis(data: Union[pd.DataFrame, pa.Table, List[Dict[str, Any]], Dict[str, Any]]) -> AnalysisResult:
    """ë¹ ë¥¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)."""
    return analyze_data(data, AnalysisConfig(verbose=True))


def comprehensive_analysis(
    data: Union[pd.DataFrame, pa.Table, List[Dict[str, Any]], Dict[str, Any]]
) -> AnalysisResult:
    """ì¢…í•© ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”)."""
    config = AnalysisConfig(
        enable_data_integration=True,
        include_descriptive_stats=True,
        include_correlation_analysis=True,
        include_distribution_analysis=True,
        include_quality_metrics=True,
        generate_charts=True,
        generate_dashboard=True,
        generate_report=True,
        quality_threshold=0.8,
        verbose=True,
    )
    return analyze_data(data, config)


def quality_focused_analysis(
    data: Union[pd.DataFrame, pa.Table, List[Dict[str, Any]], Dict[str, Any]]
) -> AnalysisResult:
    """í’ˆì§ˆ ì¤‘ì‹¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    config = AnalysisConfig(
        include_descriptive_stats=True,
        include_quality_metrics=True,
        quality_threshold=0.9,
        generate_charts=False,
        generate_dashboard=False,
        generate_report=False,
        verbose=True,
    )
    return analyze_data(data, config)


def visualization_focused_analysis(
    data: Union[pd.DataFrame, pa.Table, List[Dict[str, Any]], Dict[str, Any]]
) -> AnalysisResult:
    """ì‹œê°í™” ì¤‘ì‹¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    config = AnalysisConfig(
        include_descriptive_stats=True,
        include_correlation_analysis=True,
        include_quality_metrics=False,
        generate_charts=True,
        generate_dashboard=True,
        generate_report=True,
        verbose=True,
    )
    return analyze_data(data, config)
