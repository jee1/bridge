#!/usr/bin/env python3
"""C1 ë§ˆì¼ìŠ¤í†¤ìš© ëŒ€ìš©ëŸ‰ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ - Bridge Analytics í…ŒìŠ¤íŠ¸ìš©"""

import asyncio
import json
import os
import sys
import random
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from faker import Faker
import numpy as np

# ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ë“¤
import asyncpg
import aiomysql
from elasticsearch import Elasticsearch

# í•œêµ­ì–´ Faker ì„¤ì •
fake = Faker('ko_KR')

class C1SampleDataGenerator:
    """C1 ë§ˆì¼ìŠ¤í†¤ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±ê¸°"""
    
    def __init__(self, scale: str = "medium"):
        """
        Args:
            scale: ë°ì´í„° í¬ê¸° ("small", "medium", "large", "xlarge")
        """
        self.scale = scale
        self.data_sizes = {
            "small": {"customers": 1000, "products": 100, "orders": 5000, "sales": 3000, "activities": 2000},
            "medium": {"customers": 10000, "products": 500, "orders": 50000, "sales": 30000, "activities": 20000},
            "large": {"customers": 100000, "products": 2000, "orders": 500000, "sales": 300000, "activities": 200000},
            "xlarge": {"customers": 1000000, "products": 10000, "orders": 5000000, "sales": 3000000, "activities": 2000000}
        }
        self.sizes = self.data_sizes[scale]
        
        # í•œêµ­ ë„ì‹œ ëª©ë¡
        self.korean_cities = [
            "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…",
            "ìˆ˜ì›", "ê³ ì–‘", "ìš©ì¸", "ì„±ë‚¨", "ë¶€ì²œ", "í™”ì„±", "ì•ˆì‚°", "ì•ˆì–‘",
            "í‰íƒ", "ì‹œí¥", "ê¹€í¬", "ì˜ì •ë¶€", "ê´‘ëª…", "ê³¼ì²œ", "ì˜¤ì‚°", "ì˜ì™•",
            "í•˜ë‚¨", "ì´ì²œ", "ì•ˆì„±", "í¬ì²œ", "ì—¬ì£¼", "ì–‘í‰", "ë™ë‘ì²œ", "ê°€í‰",
            "ì—°ì²œ", "ì¶˜ì²œ", "ì›ì£¼", "ê°•ë¦‰", "íƒœë°±", "ì†ì´ˆ", "ì‚¼ì²™", "í™ì²œ",
            "íš¡ì„±", "ì˜ì›”", "í‰ì°½", "ì •ì„ ", "ì² ì›", "í™”ì²œ", "ì–‘êµ¬", "ì¸ì œ"
        ]
        
        # ìƒí’ˆ ì¹´í…Œê³ ë¦¬
        self.product_categories = [
            "ì „ìì œí’ˆ", "ê°€êµ¬", "ì˜ë¥˜", "í™”ì¥í’ˆ", "ì‹í’ˆ", "ë„ì„œ", "ìŠ¤í¬ì¸ ìš©í’ˆ",
            "ìë™ì°¨ìš©í’ˆ", "ìƒí™œìš©í’ˆ", "ì™„êµ¬", "ë°˜ë ¤ë™ë¬¼ìš©í’ˆ", "ê±´ê°•ìš©í’ˆ"
        ]
        
        # ì§€ì—­ ì •ë³´
        self.regions = [
            {"name": "ì„œìš¸", "country": "í•œêµ­", "population": 9720846, "gdp_per_capita": 35000},
            {"name": "ë¶€ì‚°", "country": "í•œêµ­", "population": 3448737, "gdp_per_capita": 28000},
            {"name": "ëŒ€êµ¬", "country": "í•œêµ­", "population": 2413076, "gdp_per_capita": 25000},
            {"name": "ì¸ì²œ", "country": "í•œêµ­", "population": 2954314, "gdp_per_capita": 30000},
            {"name": "ê´‘ì£¼", "country": "í•œêµ­", "population": 1441970, "gdp_per_capita": 22000},
            {"name": "ëŒ€ì „", "country": "í•œêµ­", "population": 1441970, "gdp_per_capita": 26000},
            {"name": "ìš¸ì‚°", "country": "í•œêµ­", "population": 1142190, "gdp_per_capita": 32000},
            {"name": "ì„¸ì¢…", "country": "í•œêµ­", "population": 365339, "gdp_per_capita": 40000}
        ]

    async def init_postgres_c1_data(self):
        """PostgreSQLì— C1ìš© ê³ ê° ë°ì´í„° ìƒì„±"""
        print("ğŸ˜ PostgreSQL C1 ë°ì´í„° ìƒì„± ì‹œì‘...")
        
        postgres_config = {
            "host": os.getenv("BRIDGE_POSTGRES_HOST", "localhost"),
            "port": int(os.getenv("BRIDGE_POSTGRES_PORT", "5432")),
            "database": os.getenv("BRIDGE_POSTGRES_DB", "bridge_dev"),
            "user": os.getenv("BRIDGE_POSTGRES_USER", "bridge_user"),
            "password": os.getenv("BRIDGE_POSTGRES_PASSWORD", "bridge_password"),
        }
        
        try:
            conn = await asyncpg.connect(**postgres_config)
            print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
            
            # analytics_db ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            try:
                await conn.execute("CREATE DATABASE analytics_db;")
            except asyncpg.exceptions.DuplicateDatabaseError:
                pass  # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            await conn.close()
            
            postgres_config["database"] = "analytics_db"
            conn = await asyncpg.connect(**postgres_config)
            
            # í…Œì´ë¸” ìƒì„±
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS customers (
                    id SERIAL PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    email VARCHAR(100) UNIQUE NOT NULL,
                    age INTEGER,
                    city VARCHAR(50),
                    registration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    vip_status BOOLEAN DEFAULT FALSE,
                    total_spent DECIMAL(12,2) DEFAULT 0,
                    last_purchase_date TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS products (
                    id SERIAL PRIMARY KEY,
                    name VARCHAR(200) NOT NULL,
                    category VARCHAR(50),
                    price DECIMAL(10,2) NOT NULL,
                    stock_quantity INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS orders (
                    id SERIAL PRIMARY KEY,
                    customer_id INTEGER REFERENCES customers(id),
                    product_id INTEGER REFERENCES products(id),
                    amount DECIMAL(10,2) NOT NULL,
                    quantity INTEGER NOT NULL,
                    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    status VARCHAR(20) DEFAULT 'pending',
                    payment_method VARCHAR(50),
                    shipping_address TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS customer_segments (
                    id SERIAL PRIMARY KEY,
                    customer_id INTEGER REFERENCES customers(id),
                    segment_name VARCHAR(50) NOT NULL,
                    score DECIMAL(5,2),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            print("âœ… PostgreSQL í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ê³ ë ¤í•˜ì—¬ ìˆœì„œëŒ€ë¡œ)
            # í…Œì´ë¸”ì„ ë“œë¡­í•˜ê³  ì¬ìƒì„±í•˜ì—¬ ì™„ì „íˆ ì´ˆê¸°í™”
            await conn.execute("DROP TABLE IF EXISTS customer_segments CASCADE;")
            await conn.execute("DROP TABLE IF EXISTS orders CASCADE;")
            await conn.execute("DROP TABLE IF EXISTS products CASCADE;")
            await conn.execute("DROP TABLE IF EXISTS customers CASCADE;")
            
            # í…Œì´ë¸” ì¬ìƒì„±
            await conn.execute("""
                CREATE TABLE customers (
                    id SERIAL PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    email VARCHAR(100) UNIQUE NOT NULL,
                    age INTEGER,
                    city VARCHAR(50),
                    registration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    vip_status BOOLEAN DEFAULT FALSE,
                    total_spent DECIMAL(12,2) DEFAULT 0,
                    last_purchase_date TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE products (
                    id SERIAL PRIMARY KEY,
                    name VARCHAR(200) NOT NULL,
                    category VARCHAR(50),
                    price DECIMAL(10,2) NOT NULL,
                    stock_quantity INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE orders (
                    id SERIAL PRIMARY KEY,
                    customer_id INTEGER REFERENCES customers(id),
                    product_id INTEGER REFERENCES products(id),
                    amount DECIMAL(10,2) NOT NULL,
                    quantity INTEGER NOT NULL,
                    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    status VARCHAR(20) DEFAULT 'pending',
                    payment_method VARCHAR(50),
                    shipping_address TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await conn.execute("""
                CREATE TABLE customer_segments (
                    id SERIAL PRIMARY KEY,
                    customer_id INTEGER REFERENCES customers(id),
                    segment_name VARCHAR(50) NOT NULL,
                    score DECIMAL(5,2),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # ê³ ê° ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ê³ ê° ë°ì´í„° ìƒì„± ì¤‘... ({self.sizes['customers']:,}ëª…)")
            customers_data = []
            used_emails = set()  # ì¤‘ë³µ ì´ë©”ì¼ ë°©ì§€
            
            for i in range(self.sizes['customers']):
                # ì—°ë ¹ ë¶„í¬: 20-70ì„¸, ì •ê·œë¶„í¬
                age = max(20, min(70, int(np.random.normal(40, 15))))
                
                # VIP ê³ ê° ë¹„ìœ¨ 5%
                vip_status = random.random() < 0.05
                
                # ë“±ë¡ì¼: ìµœê·¼ 3ë…„ ë‚´
                registration_date = fake.date_time_between(start_date='-3y', end_date='now')
                
                # ê³ ìœ í•œ ì´ë©”ì¼ ìƒì„±
                email = fake.email()
                while email in used_emails:
                    email = fake.email()
                used_emails.add(email)
                
                customers_data.append((
                    fake.name(),
                    email,
                    age,
                    random.choice(self.korean_cities),
                    registration_date,
                    vip_status,
                    0,  # total_spentëŠ” ë‚˜ì¤‘ì— ê³„ì‚°
                    None  # last_purchase_dateëŠ” ë‚˜ì¤‘ì— ì„¤ì •
                ))
            
            # ê³ ê° ë°ì´í„° ì‚½ì…
            await conn.executemany(
                "INSERT INTO customers (name, email, age, city, registration_date, vip_status, total_spent, last_purchase_date) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)",
                customers_data
            )
            print(f"âœ… {len(customers_data):,}ëª…ì˜ ê³ ê° ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            # ìƒí’ˆ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ìƒí’ˆ ë°ì´í„° ìƒì„± ì¤‘... ({self.sizes['products']:,}ê°œ)")
            products_data = []
            for i in range(self.sizes['products']):
                category = random.choice(self.product_categories)
                
                # ì¹´í…Œê³ ë¦¬ë³„ ê°€ê²© ë¶„í¬
                if category == "ì „ìì œí’ˆ":
                    price = random.uniform(50000, 2000000)
                elif category == "ê°€êµ¬":
                    price = random.uniform(100000, 1000000)
                elif category == "ì˜ë¥˜":
                    price = random.uniform(10000, 200000)
                elif category == "í™”ì¥í’ˆ":
                    price = random.uniform(5000, 100000)
                else:
                    price = random.uniform(1000, 500000)
                
                products_data.append((
                    fake.catch_phrase(),
                    category,
                    round(price, 2),
                    random.randint(0, 1000)
                ))
            
            await conn.executemany(
                "INSERT INTO products (name, category, price, stock_quantity) VALUES ($1, $2, $3, $4)",
                products_data
            )
            print(f"âœ… {len(products_data):,}ê°œì˜ ìƒí’ˆ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            # ì£¼ë¬¸ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ì£¼ë¬¸ ë°ì´í„° ìƒì„± ì¤‘... ({self.sizes['orders']:,}ê°œ)")
            orders_data = []
            customer_totals = {}  # ê³ ê°ë³„ ì´ êµ¬ë§¤ì•¡ ì¶”ì 
            
            for i in range(self.sizes['orders']):
                customer_id = random.randint(1, self.sizes['customers'])
                product_id = random.randint(1, self.sizes['products'])
                
                # ìƒí’ˆ ê°€ê²© ì¡°íšŒ (ì‹¤ì œë¡œëŠ” JOINì´ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ê·¼ì‚¬ì¹˜)
                base_price = random.uniform(1000, 1000000)
                quantity = random.randint(1, 10)
                amount = base_price * quantity
                
                # ì£¼ë¬¸ì¼: ìµœê·¼ 2ë…„ ë‚´
                order_date = fake.date_time_between(start_date='-2y', end_date='now')
                
                # ê²°ì œ ë°©ë²•
                payment_methods = ['ì¹´ë“œ', 'í˜„ê¸ˆ', 'ê³„ì¢Œì´ì²´', 'ê°„í¸ê²°ì œ', 'í¬ì¸íŠ¸']
                payment_method = random.choice(payment_methods)
                
                # ì£¼ë¬¸ ìƒíƒœ
                statuses = ['completed', 'pending', 'shipped', 'cancelled']
                status_weights = [0.7, 0.1, 0.15, 0.05]  # completedê°€ ê°€ì¥ ë§ìŒ
                status = np.random.choice(statuses, p=status_weights)
                
                orders_data.append((
                    customer_id,
                    product_id,
                    round(amount, 2),
                    quantity,
                    order_date,
                    status,
                    payment_method,
                    fake.address()
                ))
                
                # ê³ ê°ë³„ ì´ êµ¬ë§¤ì•¡ ì—…ë°ì´íŠ¸
                if status == 'completed':
                    if customer_id not in customer_totals:
                        customer_totals[customer_id] = 0
                    customer_totals[customer_id] += amount
            
            await conn.executemany(
                "INSERT INTO orders (customer_id, product_id, amount, quantity, order_date, status, payment_method, shipping_address) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)",
                orders_data
            )
            print(f"âœ… {len(orders_data):,}ê°œì˜ ì£¼ë¬¸ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            # ê³ ê°ë³„ ì´ êµ¬ë§¤ì•¡ ë° ë§ˆì§€ë§‰ êµ¬ë§¤ì¼ ì—…ë°ì´íŠ¸
            print("ğŸ“Š ê³ ê° í†µê³„ ì—…ë°ì´íŠ¸ ì¤‘...")
            for customer_id, total_spent in customer_totals.items():
                # ë§ˆì§€ë§‰ êµ¬ë§¤ì¼ ì¡°íšŒ
                last_purchase = await conn.fetchval(
                    "SELECT MAX(order_date) FROM orders WHERE customer_id = $1 AND status = 'completed'",
                    customer_id
                )
                
                await conn.execute(
                    "UPDATE customers SET total_spent = $1, last_purchase_date = $2 WHERE id = $3",
                    total_spent, last_purchase, customer_id
                )
            
            # ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            print("ğŸ“Š ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì¤‘...")
            segments_data = []
            for customer_id in range(1, self.sizes['customers'] + 1):
                # ê³ ê° ì •ë³´ ì¡°íšŒ
                customer = await conn.fetchrow("SELECT total_spent, vip_status FROM customers WHERE id = $1", customer_id)
                if customer:
                    total_spent = customer['total_spent'] or 0
                    vip_status = customer['vip_status']
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ ê²°ì •
                    if vip_status or total_spent > 1000000:
                        segment_name = "VIP"
                        score = random.uniform(90, 100)
                    elif total_spent > 500000:
                        segment_name = "Premium"
                        score = random.uniform(80, 89)
                    elif total_spent > 100000:
                        segment_name = "Standard"
                        score = random.uniform(60, 79)
                    else:
                        segment_name = "Basic"
                        score = random.uniform(40, 59)
                    
                    segments_data.append((customer_id, segment_name, round(score, 2)))
            
            await conn.executemany(
                "INSERT INTO customer_segments (customer_id, segment_name, score) VALUES ($1, $2, $3)",
                segments_data
            )
            print(f"âœ… {len(segments_data):,}ê°œì˜ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì™„ë£Œ")
            
            await conn.close()
            return True
            
        except Exception as e:
            print(f"âŒ PostgreSQL C1 ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    async def init_mysql_c1_data(self):
        """MySQLì— C1ìš© ë§¤ì¶œ ë°ì´í„° ìƒì„±"""
        print("ğŸ¬ MySQL C1 ë°ì´í„° ìƒì„± ì‹œì‘...")
        
        mysql_config = {
            "host": os.getenv("BRIDGE_MYSQL_HOST", "localhost"),
            "port": int(os.getenv("BRIDGE_MYSQL_PORT", "3306")),
            "db": os.getenv("BRIDGE_MYSQL_DB", "bridge_dev"),
            "user": os.getenv("BRIDGE_MYSQL_USER", "bridge_user"),
            "password": os.getenv("BRIDGE_MYSQL_PASSWORD", "bridge_password"),
        }
        
        try:
            conn = await aiomysql.connect(**mysql_config)
            print("âœ… MySQL ì—°ê²° ì„±ê³µ")
            cursor = await conn.cursor()
            
            # í…Œì´ë¸” ìƒì„±
            await cursor.execute("""
                CREATE TABLE IF NOT EXISTS sales (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    product_id INT NOT NULL,
                    amount DECIMAL(12,2) NOT NULL,
                    quantity INT NOT NULL,
                    sale_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    region_id INT,
                    salesperson_id INT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await cursor.execute("""
                CREATE TABLE IF NOT EXISTS regions (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    country VARCHAR(50) NOT NULL,
                    population INT,
                    gdp_per_capita DECIMAL(10,2),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            await cursor.execute("""
                CREATE TABLE IF NOT EXISTS salespeople (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    department VARCHAR(50),
                    hire_date DATE,
                    salary DECIMAL(10,2),
                    performance_score DECIMAL(5,2),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            print("âœ… MySQL í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            await cursor.execute("DELETE FROM sales;")
            await cursor.execute("DELETE FROM salespeople;")
            await cursor.execute("DELETE FROM regions;")
            
            # ì§€ì—­ ë°ì´í„° ìƒì„±
            print("ğŸ“Š ì§€ì—­ ë°ì´í„° ìƒì„± ì¤‘...")
            regions_data = []
            for i, region in enumerate(self.regions, 1):
                regions_data.append((
                    region['name'],
                    region['country'],
                    region['population'],
                    region['gdp_per_capita']
                ))
            
            await cursor.executemany(
                "INSERT INTO regions (name, country, population, gdp_per_capita) VALUES (%s, %s, %s, %s)",
                regions_data
            )
            print(f"âœ… {len(regions_data)}ê°œì˜ ì§€ì—­ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            # ì˜ì—…ì‚¬ì› ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ì˜ì—…ì‚¬ì› ë°ì´í„° ìƒì„± ì¤‘... ({self.sizes['customers'] // 100:,}ëª…)")
            salespeople_data = []
            departments = ['ì˜ì—…1íŒ€', 'ì˜ì—…2íŒ€', 'ì˜ì—…3íŒ€', 'ë§ˆì¼€íŒ…íŒ€', 'ê³ ê°ê´€ë¦¬íŒ€']
            
            for i in range(self.sizes['customers'] // 100):  # ê³ ê° 100ëª…ë‹¹ ì˜ì—…ì‚¬ì› 1ëª…
                hire_date = fake.date_between(start_date='-5y', end_date='-1y')
                salary = random.uniform(30000000, 80000000)  # 3ì²œë§Œì› ~ 8ì²œë§Œì›
                performance_score = random.uniform(60, 100)
                
                salespeople_data.append((
                    fake.name(),
                    random.choice(departments),
                    hire_date,
                    round(salary, 2),
                    round(performance_score, 2)
                ))
            
            await cursor.executemany(
                "INSERT INTO salespeople (name, department, hire_date, salary, performance_score) VALUES (%s, %s, %s, %s, %s)",
                salespeople_data
            )
            print(f"âœ… {len(salespeople_data):,}ëª…ì˜ ì˜ì—…ì‚¬ì› ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            # ë§¤ì¶œ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ë§¤ì¶œ ë°ì´í„° ìƒì„± ì¤‘... ({self.sizes['sales']:,}ê°œ)")
            sales_data = []
            
            for i in range(self.sizes['sales']):
                # ìƒí’ˆ ID (PostgreSQLì˜ products í…Œì´ë¸”ê³¼ ì—°ë™)
                product_id = random.randint(1, self.sizes['products'])
                
                # ë§¤ì¶œ ê¸ˆì•¡ (ì •ê·œë¶„í¬ + ì´ìƒì¹˜)
                if random.random() < 0.02:  # 2% í™•ë¥ ë¡œ ì´ìƒì¹˜
                    amount = random.uniform(1000000, 10000000)  # 100ë§Œì› ~ 1000ë§Œì›
                else:
                    amount = random.uniform(10000, 500000)  # 1ë§Œì› ~ 50ë§Œì›
                
                quantity = random.randint(1, 20)
                region_id = random.randint(1, len(self.regions))
                salesperson_id = random.randint(1, len(salespeople_data))
                
                # ë§¤ì¶œì¼: ìµœê·¼ 2ë…„ ë‚´
                sale_date = fake.date_time_between(start_date='-2y', end_date='now')
                
                sales_data.append((
                    product_id,
                    round(amount, 2),
                    quantity,
                    sale_date,
                    region_id,
                    salesperson_id
                ))
            
            await cursor.executemany(
                "INSERT INTO sales (product_id, amount, quantity, sale_date, region_id, salesperson_id) VALUES (%s, %s, %s, %s, %s, %s)",
                sales_data
            )
            print(f"âœ… {len(sales_data):,}ê°œì˜ ë§¤ì¶œ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
            
            await conn.commit()
            await cursor.close()
            conn.close()
            return True
            
        except Exception as e:
            print(f"âŒ MySQL C1 ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    async def init_elasticsearch_c1_data(self):
        """Elasticsearchì— C1ìš© ë¡œê·¸ ë°ì´í„° ìƒì„±"""
        print("ğŸ” Elasticsearch C1 ë°ì´í„° ìƒì„± ì‹œì‘...")
        
        # Elasticsearch URL êµ¬ì„± - scheme í¬í•¨
        es_host = os.getenv('BRIDGE_ELASTICSEARCH_HOST', 'localhost')
        es_port = os.getenv('BRIDGE_ELASTICSEARCH_PORT', '9200')
        es_use_ssl = os.getenv('BRIDGE_ELASTICSEARCH_USE_SSL', 'false').lower() == 'true'
        
        scheme = 'https' if es_use_ssl else 'http'
        es_url = f"{scheme}://{es_host}:{es_port}"
        
        es_config = {
            "hosts": [es_url],
            "verify_certs": False,
            "request_timeout": 30,
            "retry_on_timeout": True,
            "max_retries": 3,
            "api_key": None,  # Disable API key
            "http_compress": False,  # Disable compression
        }
        
        username = os.getenv('BRIDGE_ELASTICSEARCH_USERNAME')
        password = os.getenv('BRIDGE_ELASTICSEARCH_PASSWORD')
        if username and password:
            es_config["basic_auth"] = (username, password)
        
        try:
            print(f"ğŸ”— Elasticsearch ì—°ê²° ì‹œë„: {es_url}")
            es = Elasticsearch(**es_config)
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                ping_result = es.ping()
                if not ping_result:
                    print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨ - ping ì‹¤íŒ¨")
                    return False
            except Exception as e:
                print(f"âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨ - ping ì˜¤ë¥˜: {e}")
                print(f"ğŸ”§ ì—°ê²° ì„¤ì •: {es_config}")
                return False
            
            print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ")
            
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
            indices_to_delete = ["user_activity", "error_logs", "sales_events"]
            for index in indices_to_delete:
                try:
                    if es.indices.exists(index=index):
                        es.indices.delete(index=index)
                        print(f"ğŸ—‘ï¸  ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ: {index}")
                except Exception as e:
                    print(f"âš ï¸  ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ({index}): {e}")
            
            # 1. ì‚¬ìš©ì í™œë™ ë¡œê·¸ ì¸ë±ìŠ¤ ìƒì„±
            user_activity_mapping = {
                "mappings": {
                    "properties": {
                        "timestamp": {"type": "date"},
                        "user_id": {"type": "integer"},
                        "action": {"type": "keyword"},
                        "page": {"type": "text"},
                        "duration": {"type": "integer"},
                        "device": {"type": "keyword"},
                        "browser": {"type": "keyword"},
                        "location": {"type": "geo_point"},
                        "ip_address": {"type": "ip"},
                        "session_id": {"type": "keyword"}
                    }
                }
            }
            
            es.indices.create(index="user_activity", body=user_activity_mapping)
            print("âœ… user_activity ì¸ë±ìŠ¤ ìƒì„±")
            
            # ì‚¬ìš©ì í™œë™ ë¡œê·¸ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ì‚¬ìš©ì í™œë™ ë¡œê·¸ ìƒì„± ì¤‘... ({self.sizes['activities']:,}ê°œ)")
            actions = ['login', 'logout', 'view_product', 'add_to_cart', 'purchase', 'search', 'browse']
            pages = ['/home', '/products', '/cart', '/checkout', '/profile', '/search', '/category']
            devices = ['desktop', 'mobile', 'tablet']
            browsers = ['Chrome', 'Firefox', 'Safari', 'Edge', 'Opera']
            
            for i in range(self.sizes['activities']):
                user_id = random.randint(1, self.sizes['customers'])
                action = random.choice(actions)
                page = random.choice(pages)
                duration = random.randint(1, 300)  # 1ì´ˆ ~ 5ë¶„
                device = random.choice(devices)
                browser = random.choice(browsers)
                
                # ìœ„ì¹˜ (í•œêµ­ ë‚´)
                lat = random.uniform(33.0, 38.5)
                lon = random.uniform(124.0, 132.0)
                
                activity_data = {
                    "timestamp": fake.date_time_between(start_date='-1y', end_date='now').isoformat() + "Z",
                    "user_id": user_id,
                    "action": action,
                    "page": page,
                    "duration": duration,
                    "device": device,
                    "browser": browser,
                    "location": {"lat": lat, "lon": lon},
                    "ip_address": fake.ipv4(),
                    "session_id": fake.uuid4()
                }
                
                es.index(index="user_activity", body=activity_data)
                
                if (i + 1) % 10000 == 0:
                    print(f"  ì§„í–‰ë¥ : {i + 1:,}/{self.sizes['activities']:,} ({((i + 1) / self.sizes['activities']) * 100:.1f}%)")
            
            print(f"âœ… {self.sizes['activities']:,}ê°œì˜ ì‚¬ìš©ì í™œë™ ë¡œê·¸ ìƒì„± ì™„ë£Œ")
            
            # 2. ì—ëŸ¬ ë¡œê·¸ ì¸ë±ìŠ¤ ìƒì„±
            error_logs_mapping = {
                "mappings": {
                    "properties": {
                        "timestamp": {"type": "date"},
                        "level": {"type": "keyword"},
                        "message": {"type": "text"},
                        "service": {"type": "keyword"},
                        "stack_trace": {"type": "text"},
                        "user_id": {"type": "integer"},
                        "request_id": {"type": "keyword"},
                        "error_code": {"type": "keyword"}
                    }
                }
            }
            
            es.indices.create(index="error_logs", body=error_logs_mapping)
            print("âœ… error_logs ì¸ë±ìŠ¤ ìƒì„±")
            
            # ì—ëŸ¬ ë¡œê·¸ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ì—ëŸ¬ ë¡œê·¸ ìƒì„± ì¤‘... ({self.sizes['activities'] // 100:,}ê°œ)")
            levels = ['ERROR', 'WARNING', 'CRITICAL']
            services = ['api-gateway', 'user-service', 'order-service', 'payment-service', 'notification-service']
            error_codes = ['500', '404', '403', '401', '400', 'TIMEOUT', 'CONNECTION_ERROR']
            
            for i in range(self.sizes['activities'] // 100):  # í™œë™ì˜ 1%ê°€ ì—ëŸ¬
                level = random.choice(levels)
                service = random.choice(services)
                error_code = random.choice(error_codes)
                user_id = random.randint(1, self.sizes['customers']) if random.random() < 0.7 else None
                
                error_data = {
                    "timestamp": fake.date_time_between(start_date='-1y', end_date='now').isoformat() + "Z",
                    "level": level,
                    "message": fake.sentence(),
                    "service": service,
                    "stack_trace": fake.text(max_nb_chars=500),
                    "user_id": user_id,
                    "request_id": fake.uuid4(),
                    "error_code": error_code
                }
                
                es.index(index="error_logs", body=error_data)
            
            print(f"âœ… {self.sizes['activities'] // 100:,}ê°œì˜ ì—ëŸ¬ ë¡œê·¸ ìƒì„± ì™„ë£Œ")
            
            # 3. ë§¤ì¶œ ì´ë²¤íŠ¸ ì¸ë±ìŠ¤ ìƒì„±
            sales_events_mapping = {
                "mappings": {
                    "properties": {
                        "timestamp": {"type": "date"},
                        "event_type": {"type": "keyword"},
                        "product_id": {"type": "integer"},
                        "amount": {"type": "float"},
                        "quantity": {"type": "integer"},
                        "region": {"type": "keyword"},
                        "salesperson_id": {"type": "integer"},
                        "customer_id": {"type": "integer"},
                        "metadata": {"type": "object"}
                    }
                }
            }
            
            es.indices.create(index="sales_events", body=sales_events_mapping)
            print("âœ… sales_events ì¸ë±ìŠ¤ ìƒì„±")
            
            # ë§¤ì¶œ ì´ë²¤íŠ¸ ë°ì´í„° ìƒì„±
            print(f"ğŸ“Š ë§¤ì¶œ ì´ë²¤íŠ¸ ìƒì„± ì¤‘... ({self.sizes['sales'] // 10:,}ê°œ)")
            event_types = ['sale_completed', 'sale_cancelled', 'refund_processed', 'payment_failed']
            
            for i in range(self.sizes['sales'] // 10):  # ë§¤ì¶œì˜ 10%ê°€ ì´ë²¤íŠ¸
                event_type = random.choice(event_types)
                product_id = random.randint(1, self.sizes['products'])
                amount = random.uniform(10000, 1000000)
                quantity = random.randint(1, 10)
                region = random.choice(self.korean_cities)
                salesperson_id = random.randint(1, self.sizes['customers'] // 100)
                customer_id = random.randint(1, self.sizes['customers'])
                
                event_data = {
                    "timestamp": fake.date_time_between(start_date='-2y', end_date='now').isoformat() + "Z",
                    "event_type": event_type,
                    "product_id": product_id,
                    "amount": round(amount, 2),
                    "quantity": quantity,
                    "region": region,
                    "salesperson_id": salesperson_id,
                    "customer_id": customer_id,
                    "metadata": {
                        "payment_method": random.choice(['ì¹´ë“œ', 'í˜„ê¸ˆ', 'ê³„ì¢Œì´ì²´']),
                        "discount_applied": random.random() < 0.3,
                        "promotion_code": fake.word() if random.random() < 0.2 else None
                    }
                }
                
                es.index(index="sales_events", body=event_data)
            
            print(f"âœ… {self.sizes['sales'] // 10:,}ê°œì˜ ë§¤ì¶œ ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ")
            
            # ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨
            es.indices.refresh(index="_all")
            print("âœ… ëª¨ë“  ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
            
            # í†µê³„ ì¶œë ¥
            stats = es.indices.stats(index="_all")
            total_docs = sum(index_stats["total"]["docs"]["count"] for index_stats in stats["indices"].values())
            print(f"ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {total_docs:,}")
            
            es.close()
            return True
            
        except Exception as e:
            print(f"âŒ Elasticsearch C1 ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def print_data_summary(self):
        """ìƒì„±ëœ ë°ì´í„° ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š C1 ë§ˆì¼ìŠ¤í†¤ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        print("="*60)
        print(f"ğŸ“ˆ ë°ì´í„° ê·œëª¨: {self.scale.upper()}")
        print(f"ğŸ‘¥ ê³ ê° ìˆ˜: {self.sizes['customers']:,}ëª…")
        print(f"ğŸ›ï¸  ìƒí’ˆ ìˆ˜: {self.sizes['products']:,}ê°œ")
        print(f"ğŸ“¦ ì£¼ë¬¸ ìˆ˜: {self.sizes['orders']:,}ê°œ")
        print(f"ğŸ’° ë§¤ì¶œ ìˆ˜: {self.sizes['sales']:,}ê°œ")
        print(f"ğŸ“± í™œë™ ë¡œê·¸: {self.sizes['activities']:,}ê°œ")
        print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ C1 ê¸°ëŠ¥ë“¤:")
        print("  â€¢ ë°ì´í„° í†µí•© (í¬ë¡œìŠ¤ ì†ŒìŠ¤ ì¡°ì¸)")
        print("  â€¢ ê¸°ë³¸ í†µê³„ ë¶„ì„ (í‰ê· , ì¤‘ì•™ê°’, í‘œì¤€í¸ì°¨)")
        print("  â€¢ ìƒê´€ê´€ê³„ ë¶„ì„ (ê³ ê°-ìƒí’ˆ, ì§€ì—­-ë§¤ì¶œ)")
        print("  â€¢ ì´ìƒì¹˜ íƒì§€ (ë§¤ì¶œ, í™œë™ íŒ¨í„´)")
        print("  â€¢ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ (ê²°ì¸¡ê°’, ì¤‘ë³µê°’)")
        print("  â€¢ ì‹œê°í™” (ê³ ê° ì„¸ê·¸ë¨¼íŠ¸, ë§¤ì¶œ íŠ¸ë Œë“œ)")
        print("  â€¢ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬)")
        print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        print("  make c1-test      # C1 ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("  make c1-benchmark # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰")

async def main():
    """ë©”ì¸ í•¨ìˆ˜ - C1 ë§ˆì¼ìŠ¤í†¤ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    import argparse
    
    parser = argparse.ArgumentParser(description='C1 ë§ˆì¼ìŠ¤í†¤ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±')
    parser.add_argument('--scale', choices=['small', 'medium', 'large', 'xlarge'], 
                       default='medium', help='ë°ì´í„° í¬ê¸° (ê¸°ë³¸: medium)')
    args = parser.parse_args()
    
    print("ğŸš€ C1 ë§ˆì¼ìŠ¤í†¤ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹œì‘...")
    print(f"ğŸ“Š ë°ì´í„° ê·œëª¨: {args.scale.upper()}")
    print("="*60)
    
    generator = C1SampleDataGenerator(scale=args.scale)
    
    # ê° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    postgres_success = await generator.init_postgres_c1_data()
    print()
    
    mysql_success = await generator.init_mysql_c1_data()
    print()
    
    elasticsearch_success = await generator.init_elasticsearch_c1_data()
    print()
    
    print("="*60)
    print("ğŸ“Š C1 ë°ì´í„° ìƒì„± ê²°ê³¼:")
    print(f"  PostgreSQL: {'âœ… ì„±ê³µ' if postgres_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  MySQL:      {'âœ… ì„±ê³µ' if mysql_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  Elasticsearch: {'âœ… ì„±ê³µ' if elasticsearch_success else 'âŒ ì‹¤íŒ¨'}")
    
    if postgres_success and mysql_success and elasticsearch_success:
        generator.print_data_summary()
        sys.exit(0)
    else:
        print("\nâŒ ì¼ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨!")
        print("Docker ì„œë¹„ìŠ¤ë“¤ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())