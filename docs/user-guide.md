# Bridge ì‚¬ìš©ì ê°€ì´ë“œ

## ğŸ“– ê°œìš”

BridgeëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì— ëŒ€í•œ í‘œì¤€í™”ëœ ì ‘ê·¼ì„ ì œê³µí•˜ê³ , AI ì—ì´ì „íŠ¸ê°€ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê³  íˆ¬ëª…í•˜ê²Œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. ì„¤ì¹˜ ë° ì„¤ì •

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
make install

# ê°œë°œ ì„œë²„ ì‹¤í–‰
make dev

# MCP ì„œë²„ ì‹¤í–‰
make mcp-server
```

### 2. ê¸°ë³¸ ì‚¬ìš©ë²•

```bash
# CLIë¥¼ í†µí•œ ê¸°ë³¸ ë¶„ì„
python cli.py "ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„"

# íŠ¹ì • ë°ì´í„° ì†ŒìŠ¤ì™€ ë„êµ¬ ì§€ì •
python cli.py "í”„ë¦¬ë¯¸ì—„ ê³ ê° ë¶„ì„" --sources postgres://analytics_db --tools sql_executor,statistics_analyzer
```

## ğŸ”Œ ë°ì´í„° ì»¤ë„¥í„° ì‚¬ìš©ë²•

### PostgreSQL ì»¤ë„¥í„°

```python
from src.bridge.connectors.postgres import PostgresConnector

# ì»¤ë„¥í„° ìƒì„±
connector = PostgresConnector(
    host="localhost",
    port=5432,
    database="analytics",
    username="user",
    password="password"
)

# ì—°ê²° í…ŒìŠ¤íŠ¸
await connector.test_connection()

# ë©”íƒ€ë°ì´í„° ì¡°íšŒ
metadata = await connector.get_metadata()
print(f"í…Œì´ë¸” ìˆ˜: {len(metadata['tables'])}")

# ì¿¼ë¦¬ ì‹¤í–‰
async for row in connector.run_query("SELECT * FROM customers LIMIT 10"):
    print(row)
```

### MongoDB ì»¤ë„¥í„°

```python
from src.bridge.connectors.mongodb import MongoConnector

# ì»¤ë„¥í„° ìƒì„±
connector = MongoConnector(
    host="localhost",
    port=27017,
    database="analytics",
    username="user",
    password="password"
)

# ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ
metadata = await connector.get_metadata()
print(f"ì»¬ë ‰ì…˜ ìˆ˜: {len(metadata['collections'])}")

# ì§‘ê³„ ì¿¼ë¦¬ ì‹¤í–‰
pipeline = [
    {"$group": {"_id": "$category", "count": {"$sum": 1}}},
    {"$sort": {"count": -1}}
]
async for result in connector.run_query(pipeline):
    print(result)
```

### Elasticsearch ì»¤ë„¥í„°

```python
from src.bridge.connectors.elasticsearch import ElasticsearchConnector

# ì»¤ë„¥í„° ìƒì„±
connector = ElasticsearchConnector(
    host="localhost",
    port=9200,
    username="elastic",
    password="password"
)

# ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ
metadata = await connector.get_metadata()
print(f"ì¸ë±ìŠ¤ ìˆ˜: {len(metadata['indices'])}")

# ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
query = {
    "query": {
        "match": {
            "title": "analytics"
        }
    }
}
async for result in connector.run_query(query):
    print(result)
```

## ğŸ“Š ë¶„ì„ ë„êµ¬ ì‚¬ìš©ë²•

### í†µê³„ ë¶„ì„

```python
from src.bridge.analytics.core import StatisticsAnalyzer, UnifiedDataFrame
import pandas as pd

# ë°ì´í„° ì¤€ë¹„
data = pd.DataFrame({
    'sales': [100, 200, 150, 300, 250],
    'profit': [20, 40, 30, 60, 50],
    'region': ['North', 'South', 'North', 'East', 'West']
})

unified_df = UnifiedDataFrame(data)

# í†µê³„ ë¶„ì„ê¸° ìƒì„±
analyzer = StatisticsAnalyzer()

# ê¸°ìˆ  í†µê³„ ê³„ì‚°
stats = analyzer.calculate_descriptive_stats(unified_df, ['sales', 'profit'])
print(f"í‰ê·  ë§¤ì¶œ: {stats['sales']['mean']:.2f}")
print(f"ë§¤ì¶œ í‘œì¤€í¸ì°¨: {stats['sales']['std']:.2f}")

# ìƒê´€ê´€ê³„ ë¶„ì„
correlation = analyzer.calculate_correlation(unified_df, ['sales', 'profit'])
print(f"ë§¤ì¶œ-ì´ìµ ìƒê´€ê³„ìˆ˜: {correlation['sales']['profit']:.3f}")

# ë¶„í¬ ë¶„ì„
distribution = analyzer.calculate_distribution_stats(unified_df, 'sales')
print(f"ë§¤ì¶œ ì™œë„: {distribution['skewness']:.3f}")
print(f"ë§¤ì¶œ ì²¨ë„: {distribution['kurtosis']:.3f}")
```

### ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬

```python
from src.bridge.analytics.core import QualityChecker

# í’ˆì§ˆ ê²€ì‚¬ê¸° ìƒì„±
checker = QualityChecker()

# ê²°ì¸¡ê°’ ë¶„ì„
missing_stats = checker.analyze_missing_values(unified_df)
print(f"ê²°ì¸¡ê°’ ë¹„ìœ¨: {missing_stats.overall_missing_ratio:.2%}")

# ì´ìƒì¹˜ íƒì§€
outlier_stats = checker.detect_outliers(unified_df, 'sales', method='iqr')
print(f"ì´ìƒì¹˜ ê°œìˆ˜: {outlier_stats.outlier_count}")

# ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬
consistency_stats = checker.check_consistency(unified_df)
print(f"ì¼ê´€ì„± ì ìˆ˜: {consistency_stats.consistency_score:.2f}")

# ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸
quality_report = checker.generate_quality_report(unified_df)
print(f"ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality_report.overall_score:.2f}")
print(f"ê¶Œì¥ì‚¬í•­: {quality_report.recommendations}")
```

### ì‹œê°í™”

```python
from src.bridge.analytics.core import ChartGenerator, ChartConfig

# ì°¨íŠ¸ ìƒì„±ê¸° ìƒì„±
chart_generator = ChartGenerator()

# ë§‰ëŒ€ ì°¨íŠ¸ ìƒì„±
bar_config = ChartConfig(
    chart_type="bar",
    title="ì§€ì—­ë³„ ë§¤ì¶œ",
    x_axis="region",
    y_axis="sales"
)
bar_chart = chart_generator.create_bar_chart(unified_df, bar_config)

# ì„  ì°¨íŠ¸ ìƒì„±
line_config = ChartConfig(
    chart_type="line",
    title="ë§¤ì¶œ ì¶”ì´",
    x_axis="date",
    y_axis="sales"
)
line_chart = chart_generator.create_line_chart(unified_df, line_config)

# ì‚°ì ë„ ìƒì„±
scatter_config = ChartConfig(
    chart_type="scatter",
    title="ë§¤ì¶œ vs ì´ìµ",
    x_axis="sales",
    y_axis="profit"
)
scatter_chart = chart_generator.create_scatter_plot(unified_df, scatter_config)

# íˆìŠ¤í† ê·¸ë¨ ìƒì„±
hist_config = ChartConfig(
    chart_type="histogram",
    title="ë§¤ì¶œ ë¶„í¬",
    column="sales"
)
histogram = chart_generator.create_histogram(unified_df, hist_config)
```

### ëŒ€ì‹œë³´ë“œ ìƒì„±

```python
from src.bridge.analytics.core import DashboardGenerator, DashboardConfig

# ëŒ€ì‹œë³´ë“œ ìƒì„±ê¸° ìƒì„±
dashboard_generator = DashboardGenerator()

# ëŒ€ì‹œë³´ë“œ ì„¤ì •
dashboard_config = DashboardConfig(
    title="ë§¤ì¶œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    layout=(2, 2),
    figsize=(12, 8)
)

# ëŒ€ì‹œë³´ë“œ ìƒì„±
dashboard = dashboard_generator.create_analytics_dashboard(unified_df, dashboard_config)
```

### ë¦¬í¬íŠ¸ ìƒì„±

```python
from src.bridge.analytics.core import ReportGenerator, ReportConfig

# ë¦¬í¬íŠ¸ ìƒì„±ê¸° ìƒì„±
report_generator = ReportGenerator()

# ë¦¬í¬íŠ¸ ì„¤ì •
report_config = ReportConfig(
    title="ì›”ê°„ ë§¤ì¶œ ë¶„ì„ ë¦¬í¬íŠ¸",
    author="ë¶„ì„íŒ€",
    sections=['overview', 'statistics', 'quality', 'charts', 'dashboard']
)

# ë¦¬í¬íŠ¸ ìƒì„±
report_data = report_generator.generate_analytics_report(unified_df, report_config)
print(f"ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_data['title']}")
```

## ğŸ”’ ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ì‚¬ìš©ë²•

### ë°ì´í„° ê³„ì•½ ê´€ë¦¬

```python
from src.bridge.governance.contracts import DataContractManager, DataContract, DataField, QualityRule

# ê³„ì•½ ê´€ë¦¬ì ìƒì„±
contract_manager = DataContractManager()

# ë°ì´í„° ê³„ì•½ ìƒì„±
contract = DataContract(
    id="customer_contract",
    name="ê³ ê° ë°ì´í„° ê³„ì•½",
    version="1.0",
    description="ê³ ê° ë°ì´í„° í’ˆì§ˆ ê³„ì•½",
    data_source="postgres://analytics_db",
    table_name="customers",
    fields=[
        DataField(
            name="customer_id",
            data_type="integer",
            required=True,
            description="ê³ ê° ID"
        ),
        DataField(
            name="email",
            data_type="string",
            required=True,
            description="ì´ë©”ì¼ ì£¼ì†Œ"
        )
    ],
    quality_rules=[
        QualityRule(
            field_name="email",
            rule_type="format",
            rule_value="email",
            description="ì´ë©”ì¼ í˜•ì‹ ê²€ì¦"
        )
    ]
)

# ê³„ì•½ ë“±ë¡
contract_manager.create_contract(contract)

# ê³„ì•½ ì¡°íšŒ
retrieved_contract = contract_manager.get_contract("customer_contract")
print(f"ê³„ì•½ëª…: {retrieved_contract.name}")

# ë°ì´í„° ê²€ì¦
validation_result = contract.validate_data(customer_data)
if validation_result.is_valid:
    print("ë°ì´í„°ê°€ ê³„ì•½ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤")
else:
    print(f"ê²€ì¦ ì‹¤íŒ¨: {validation_result.errors}")
```

### ë©”íƒ€ë°ì´í„° ì¹´íƒˆë¡œê·¸

```python
from src.bridge.governance.metadata import MetadataCatalog, DataAsset, ColumnMetadata

# ë©”íƒ€ë°ì´í„° ì¹´íƒˆë¡œê·¸ ìƒì„±
catalog = MetadataCatalog()

# ë°ì´í„° ìì‚° ë“±ë¡
asset = DataAsset(
    id="customers_table",
    name="ê³ ê° í…Œì´ë¸”",
    asset_type="table",
    data_source="postgres://analytics_db",
    schema="public",
    table_name="customers",
    columns=[
        ColumnMetadata(
            name="customer_id",
            data_type="integer",
            is_primary_key=True,
            description="ê³ ê° ê³ ìœ  ì‹ë³„ì"
        ),
        ColumnMetadata(
            name="email",
            data_type="varchar",
            is_nullable=False,
            description="ê³ ê° ì´ë©”ì¼ ì£¼ì†Œ"
        )
    ],
    tags=["customer", "pii", "critical"]
)

# ìì‚° ë“±ë¡
catalog.add_asset(asset)

# ìì‚° ì¡°íšŒ
retrieved_asset = catalog.get_asset("customers_table")
print(f"ìì‚°ëª…: {retrieved_asset.name}")
print(f"ì»¬ëŸ¼ ìˆ˜: {len(retrieved_asset.columns)}")

# íƒœê·¸ë¡œ ê²€ìƒ‰
customer_assets = catalog.search_assets_by_tag("customer")
print(f"ê³ ê° ê´€ë ¨ ìì‚° ìˆ˜: {len(customer_assets)}")
```

### RBAC (ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´)

```python
from src.bridge.governance.rbac import RBACManager, Role, Permission, User

# RBAC ê´€ë¦¬ì ìƒì„±
rbac_manager = RBACManager()

# ì—­í•  ìƒì„±
analyst_role = Role(
    id="analyst",
    name="ë°ì´í„° ë¶„ì„ê°€",
    description="ë°ì´í„° ë¶„ì„ ë° ì¡°íšŒ ê¶Œí•œ",
    permissions=[
        Permission(
            resource_type="table",
            resource_id="customers",
            actions=["read", "query"]
        ),
        Permission(
            resource_type="table",
            resource_id="sales",
            actions=["read", "query", "analyze"]
        )
    ]
)

# ì‚¬ìš©ì ìƒì„±
user = User(
    id="user123",
    username="john_doe",
    email="john@example.com",
    roles=["analyst"]
)

# ì—­í•  ë° ì‚¬ìš©ì ë“±ë¡
rbac_manager.create_role(analyst_role)
rbac_manager.create_user(user)

# ì ‘ê·¼ ê¶Œí•œ í™•ì¸
has_access = rbac_manager.check_permission(
    user_id="user123",
    resource_type="table",
    resource_id="customers",
    action="read"
)
print(f"ì ‘ê·¼ ê¶Œí•œ: {has_access}")

# ì‚¬ìš©ì ì—­í•  ì¡°íšŒ
user_roles = rbac_manager.get_user_roles("user123")
print(f"ì‚¬ìš©ì ì—­í• : {[role.name for role in user_roles]}")
```

### ê°ì‚¬ ë¡œê·¸

```python
from src.bridge.governance.audit import AuditLogManager, AuditEvent

# ê°ì‚¬ ë¡œê·¸ ê´€ë¦¬ì ìƒì„±
audit_manager = AuditLogManager()

# ê°ì‚¬ ì´ë²¤íŠ¸ ìƒì„±
event = AuditEvent(
    event_type="data_access",
    user_id="user123",
    resource_type="table",
    resource_id="customers",
    action="query",
    details={
        "query": "SELECT * FROM customers WHERE region = 'North'",
        "rows_returned": 150
    }
)

# ì´ë²¤íŠ¸ ë¡œê¹…
audit_manager.log_event(event)

# ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ
recent_events = audit_manager.get_events(
    user_id="user123",
    hours=24
)
print(f"ìµœê·¼ 24ì‹œê°„ ì´ë²¤íŠ¸ ìˆ˜: {len(recent_events)}")

# ì»´í”Œë¼ì´ì–¸ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±
report = audit_manager.generate_compliance_report(
    start_date="2024-01-01",
    end_date="2024-01-31"
)
print(f"1ì›” ê°ì‚¬ ë¦¬í¬íŠ¸: {report['summary']}")
```

## ğŸ¤– ìë™í™” íŒŒì´í”„ë¼ì¸ ì‚¬ìš©ë²•

### ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§

```python
from src.bridge.automation.quality_monitor import QualityMonitor, QualityThreshold, AlertSeverity

# í’ˆì§ˆ ëª¨ë‹ˆí„° ìƒì„±
monitor = QualityMonitor(check_interval=300)  # 5ë¶„ ê°„ê²©

# ì„ê³„ê°’ ì„¤ì •
threshold = QualityThreshold(
    id="cpu_threshold",
    name="CPU ì‚¬ìš©ë¥  ì„ê³„ê°’",
    metric_type="cpu_percent",
    threshold_value=80.0,
    operator="gt",
    severity=AlertSeverity.WARNING
)

# ëª¨ë‹ˆí„°ë§ ì‘ì—… ì¶”ê°€
monitor.add_threshold(threshold)
monitor.add_monitoring_task(
    task_id="system_monitoring",
    data_source="postgres://analytics_db",
    table_name="system_metrics"
)

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
monitor.start_monitoring()

# ì•Œë¦¼ ì½œë°± ì„¤ì •
def alert_callback(alert):
    print(f"ì•Œë¦¼ ë°œìƒ: {alert.message}")

monitor.add_alert_callback(alert_callback)

# ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì¡°íšŒ
status = monitor.get_monitoring_status()
print(f"ëª¨ë‹ˆí„°ë§ ìƒíƒœ: {status['status']}")
print(f"ì„ê³„ê°’ ìˆ˜: {status['thresholds_count']}")
```

### ìë™ ë¦¬í¬íŠ¸ ìƒì„±

```python
from src.bridge.automation.report_automation import ReportAutomation, ReportTemplate, ReportSchedule, ScheduleType

# ë¦¬í¬íŠ¸ ìë™í™” ìƒì„±
automation = ReportAutomation()

# ë¦¬í¬íŠ¸ í…œí”Œë¦¿ ìƒì„±
template = ReportTemplate(
    id="daily_sales_report",
    name="ì¼ì¼ ë§¤ì¶œ ë¦¬í¬íŠ¸",
    description="ë§¤ì¼ ìë™ ìƒì„±ë˜ëŠ” ë§¤ì¶œ ë¶„ì„ ë¦¬í¬íŠ¸",
    data_source="postgres://analytics_db",
    query="SELECT * FROM daily_sales WHERE date = CURRENT_DATE",
    output_format="html"
)

# ìŠ¤ì¼€ì¤„ ìƒì„±
schedule = ReportSchedule(
    id="daily_schedule",
    template_id="daily_sales_report",
    schedule_type=ScheduleType.DAILY,
    start_time=datetime.now().replace(hour=9, minute=0, second=0)
)

# í…œí”Œë¦¿ ë° ìŠ¤ì¼€ì¤„ ë“±ë¡
automation.create_template(template)
automation.create_schedule(schedule)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
automation.start_scheduler()

# ìˆ˜ë™ ë¦¬í¬íŠ¸ ì‹¤í–‰
job_id = automation.execute_template("daily_sales_report")
print(f"ë¦¬í¬íŠ¸ ì‘ì—… ID: {job_id}")

# ì‘ì—… ìƒíƒœ ì¡°íšŒ
job = automation.get_job_status(job_id)
print(f"ì‘ì—… ìƒíƒœ: {job.status}")
```

### ì•Œë¦¼ ì‹œìŠ¤í…œ

```python
from src.bridge.automation.notification_system import NotificationSystem, AlertRule, AlertPriority

# ì•Œë¦¼ ì‹œìŠ¤í…œ ìƒì„±
notification = NotificationSystem()

# ì´ë©”ì¼ ì±„ë„ ì„¤ì •
email_config = {
    "smtp_server": "smtp.gmail.com",
    "smtp_port": 587,
    "username": "your_email@gmail.com",
    "password": "your_password",
    "from_email": "your_email@gmail.com",
    "to_emails": ["admin@example.com"]
}

notification.add_channel("email", email_config)

# ì•Œë¦¼ ê·œì¹™ ìƒì„±
rule = AlertRule(
    id="high_cpu_alert",
    name="ë†’ì€ CPU ì‚¬ìš©ë¥  ì•Œë¦¼",
    event_type="quality_alert",
    conditions={"severity": "warning"},
    channels=["email"],
    priority=AlertPriority.HIGH
)

# ê·œì¹™ ë“±ë¡
notification.add_rule(rule)

# ì•Œë¦¼ ë°œì†¡
data = {
    "severity": "warning",
    "message": "CPU ì‚¬ìš©ë¥ ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
    "value": 85.5,
    "threshold": 80.0
}

sent_messages = notification.send_notification("quality_alert", data)
print(f"ë°œì†¡ëœ ì•Œë¦¼ ìˆ˜: {len(sent_messages)}")
```

### ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬

```python
from src.bridge.automation.scheduler import TaskScheduler, ScheduledTask, TaskType

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
scheduler = TaskScheduler()

# ì‘ì—… í•¨ìˆ˜ ì •ì˜
def data_cleanup_job():
    print("ë°ì´í„° ì •ë¦¬ ì‘ì—… ì‹¤í–‰")
    # ì‹¤ì œ ì •ë¦¬ ë¡œì§
    return {"status": "completed", "cleaned_rows": 1000}

# ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ìƒì„±
task = ScheduledTask(
    id="daily_cleanup",
    name="ì¼ì¼ ë°ì´í„° ì •ë¦¬",
    description="ë§¤ì¼ ì‹¤í–‰ë˜ëŠ” ë°ì´í„° ì •ë¦¬ ì‘ì—…",
    task_type=TaskType.CLEANUP,
    function=data_cleanup_job,
    cron_expression="0 2 * * *",  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
    enabled=True
)

# ì‘ì—… ë“±ë¡
scheduler.add_task(task)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
scheduler.start_scheduler()

# ì‘ì—… ìƒíƒœ ì¡°íšŒ
status = scheduler.get_task_status("daily_cleanup")
print(f"ì‘ì—… ìƒíƒœ: {status['enabled']}")
print(f"ë‹¤ìŒ ì‹¤í–‰: {status['next_run']}")

# ì¦‰ì‹œ ì‹¤í–‰
execution_id = scheduler.execute_task_now("daily_cleanup")
print(f"ì‹¤í–‰ ID: {execution_id}")
```

## ğŸ“Š ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•

### ëŒ€ì‹œë³´ë“œ ê´€ë¦¬

```python
from src.bridge.dashboard.dashboard_manager import DashboardManager, DashboardConfig, DashboardWidget, WidgetType

# ëŒ€ì‹œë³´ë“œ ê´€ë¦¬ì ìƒì„±
dashboard_manager = DashboardManager()

# ëŒ€ì‹œë³´ë“œ ìƒì„±
config = DashboardConfig(
    id="sales_dashboard",
    name="ë§¤ì¶œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    description="ë§¤ì¶œ ê´€ë ¨ ì§€í‘œ ë° ì°¨íŠ¸ë¥¼ ë³´ì—¬ì£¼ëŠ” ëŒ€ì‹œë³´ë“œ",
    layout_type="grid",
    grid_columns=4,
    grid_rows=3
)

dashboard_manager.create_dashboard(config)

# ìœ„ì ¯ ì¶”ê°€
widget = DashboardWidget(
    id="sales_chart",
    widget_type=WidgetType.CHART,
    title="ì›”ë³„ ë§¤ì¶œ ì¶”ì´",
    position={"x": 0, "y": 0, "width": 2, "height": 1},
    config={
        "chart_type": "line",
        "data_source": "monthly_sales"
    }
)

dashboard_manager.add_widget(widget, "sales_dashboard")

# ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ
dashboard_data = dashboard_manager.get_dashboard_data("sales_dashboard")
print(f"ëŒ€ì‹œë³´ë“œëª…: {dashboard_data['name']}")
print(f"ìœ„ì ¯ ìˆ˜: {len(dashboard_data['widgets'])}")
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
from src.bridge.dashboard.real_time_monitor import RealTimeMonitor

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„° ìƒì„±
monitor = RealTimeMonitor()

# ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ë“±ë¡
monitor.register_system_collector()

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ë“±ë¡
monitor.register_application_collector()

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
monitor.start_monitoring(collection_interval=5)

# í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
client_id = "dashboard_client"
monitor.add_connection(client_id)

# ìµœì‹  ë°ì´í„° ì¡°íšŒ
data = monitor.get_latest_data(client_id)
if data:
    print(f"ë©”íŠ¸ë¦­ ìˆ˜: {len(data['metrics'])}")
    print(f"ì•Œë¦¼ ìˆ˜: {len(data['alerts'])}")

# ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì¡°íšŒ
status = monitor.get_monitoring_status()
print(f"í™œì„± ì—°ê²° ìˆ˜: {status['active_connections']}")
print(f"ìˆ˜ì§‘ê¸° ìˆ˜: {status['collectors_count']}")
```

### ì‹œê°í™” ì—”ì§„

```python
from src.bridge.dashboard.visualization_engine import VisualizationEngine, ChartConfig, ChartType

# ì‹œê°í™” ì—”ì§„ ìƒì„±
engine = VisualizationEngine()

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
cpu_data = engine.create_sample_data("cpu", 100)
memory_data = engine.create_sample_data("memory", 100)

# ëŒ€ì‹œë³´ë“œ ì„¤ì •
dashboard_config = {
    "id": "system_dashboard",
    "name": "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
    "layout_type": "grid",
    "grid_columns": 2,
    "grid_rows": 2,
    "widgets": [
        {
            "id": "cpu_chart",
            "type": "chart",
            "title": "CPU ì‚¬ìš©ë¥ ",
            "config": {
                "chart_type": "line",
                "width": 400,
                "height": 300
            }
        },
        {
            "id": "memory_metric",
            "type": "metric",
            "title": "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
            "config": {
                "width": 200,
                "height": 100
            }
        }
    ]
}

# ìœ„ì ¯ ë°ì´í„°
widgets_data = {
    "cpu_chart": cpu_data,
    "memory_metric": [{"value": 65, "unit": "%"}]
}

# ëŒ€ì‹œë³´ë“œ ë Œë”ë§
rendered_dashboard = engine.render_dashboard(dashboard_config, widgets_data)
print(f"ë Œë”ë§ ìƒíƒœ: {rendered_dashboard['status']}")
print(f"ìœ„ì ¯ ìˆ˜: {len(rendered_dashboard['layout']['widgets'])}")
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ ì»¤ë„¥í„° ê°œë°œ

```python
from src.bridge.connectors.base import BaseConnector
from typing import Dict, Any, AsyncGenerator

class CustomConnector(BaseConnector):
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
    
    async def test_connection(self) -> bool:
        # ì—°ê²° í…ŒìŠ¤íŠ¸ ë¡œì§
        try:
            # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
            return True
        except Exception:
            return False
    
    async def get_metadata(self) -> Dict[str, Any]:
        # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë¡œì§
        return {
            "tables": ["table1", "table2"],
            "version": "1.0"
        }
    
    async def run_query(self, query: str, params: Dict[str, Any] = None) -> AsyncGenerator[Dict[str, Any], None]:
        # ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§
        # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰
        yield {"result": "data"}
```

### ì»¤ìŠ¤í…€ ë¶„ì„ ë„êµ¬ ê°œë°œ

```python
from src.bridge.analytics.core import UnifiedDataFrame
from typing import Dict, Any

class CustomAnalyzer:
    def __init__(self):
        self.name = "Custom Analyzer"
    
    def analyze(self, data: UnifiedDataFrame) -> Dict[str, Any]:
        # ì»¤ìŠ¤í…€ ë¶„ì„ ë¡œì§
        pandas_df = data.to_pandas()
        
        # ë¶„ì„ ìˆ˜í–‰
        result = {
            "total_rows": len(pandas_df),
            "custom_metric": self._calculate_custom_metric(pandas_df)
        }
        
        return result
    
    def _calculate_custom_metric(self, df) -> float:
        # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê³„ì‚°
        return df.mean().mean()
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **ì—°ê²° ì˜¤ë¥˜**
   ```python
   # ì—°ê²° í…ŒìŠ¤íŠ¸
   connector = PostgresConnector(...)
   is_connected = await connector.test_connection()
   if not is_connected:
       print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
   ```

2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```python
   # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
   async for batch in connector.run_query(query, batch_size=1000):
       # ë°°ì¹˜ë³„ ì²˜ë¦¬
       process_batch(batch)
   ```

3. **ê¶Œí•œ ì˜¤ë¥˜**
   ```python
   # RBAC ê¶Œí•œ í™•ì¸
   has_permission = rbac_manager.check_permission(
       user_id="user123",
       resource_type="table",
       resource_id="customers",
       action="read"
   )
   ```

### ë¡œê·¸ í™•ì¸

```bash
# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
tail -f logs/bridge.log

# ê°ì‚¬ ë¡œê·¸
tail -f logs/audit/audit.log

# ì—ëŸ¬ ë¡œê·¸
tail -f logs/bridge_error.log
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
from src.bridge.dashboard.monitoring_dashboard import MonitoringDashboard

monitor = MonitoringDashboard()
monitor.start_monitoring()

# í˜„ì¬ ë©”íŠ¸ë¦­ ì¡°íšŒ
metrics = monitor.get_current_metrics()
print(f"CPU ì‚¬ìš©ë¥ : {metrics['system']['cpu_percent']:.1f}%")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics['system']['memory_percent']:.1f}%")
```

## ğŸ“š ì¶”ê°€ ìë£Œ

- [API ì°¸ì¡° ë¬¸ì„œ](api-reference.md)
- [ê°œë°œì ê°€ì´ë“œ](developer-guide.md)
- [ì•„í‚¤í…ì²˜ ë¬¸ì„œ](architecture.md)
- [ë³´ì•ˆ ê°€ì´ë“œ](security-guide.md)
- [ì„±ëŠ¥ íŠœë‹](performance-tuning.md)
