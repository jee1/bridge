# Bridge ML ì‚¬ìš© ê°€ì´ë“œ

## ğŸš€ ê°œìš”

Bridge MLì€ ì‹œê³„ì—´ ë¶„ì„, í´ëŸ¬ìŠ¤í„°ë§, ì´ìƒì¹˜ íƒì§€, ëª¨ë¸ ê´€ë¦¬ ë“± ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ê° ê¸°ëŠ¥ì˜ ì‚¬ìš©ë²•ê³¼ ì˜ˆì‹œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“Š ì‹œê³„ì—´ ë¶„ì„

### TimeSeriesAnalyzer ì‚¬ìš©ë²•

```python
from bridge.ml.algorithms.time_series import TimeSeriesAnalyzer, TimeSeriesResult, ForecastResult
import pandas as pd

# ì‹œê³„ì—´ ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = TimeSeriesAnalyzer()

# ë°ì´í„° ì¤€ë¹„ (pandas DataFrame)
data = pd.read_csv('sales_data.csv')
data['date'] = pd.to_datetime(data['date'])
data = data.set_index('date')

# ì •ìƒì„± ê²€ì‚¬
is_stationary, adf_stat, adf_pvalue = analyzer.analyze_stationarity(data['sales'])
print(f"ì •ìƒì„±: {is_stationary}, ADF í†µê³„: {adf_stat:.4f}, p-value: {adf_pvalue:.4f}")

# ARIMA ëª¨ë¸ í›ˆë ¨
arima_result = analyzer.fit_arima(data['sales'], order=(1, 1, 1))
print(f"ARIMA ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {arima_result.model_type}")

# Prophet ëª¨ë¸ í›ˆë ¨
prophet_result = analyzer.fit_prophet(data['sales'], seasonality_mode='multiplicative')
print(f"Prophet ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {prophet_result.model_type}")

# LSTM ëª¨ë¸ í›ˆë ¨
lstm_result = analyzer.fit_lstm(data['sales'], sequence_length=30, epochs=100)
print(f"LSTM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {lstm_result.model_type}")

# ì˜ˆì¸¡ ìˆ˜í–‰
forecast = analyzer.forecast(arima_result, periods=30)
print(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(forecast.forecast_values)}ê°œ ê¸°ê°„")
```

### ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ í™œìš©

```python
# ê²°ê³¼ ê²€ì¦
if arima_result.is_stationary:
    print("ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•©ë‹ˆë‹¤")

# ì‹ ë¢°êµ¬ê°„ í™•ì¸
if arima_result.confidence_intervals:
    lower, upper = arima_result.confidence_intervals
    print(f"ì‹ ë¢°êµ¬ê°„: {lower} ~ {upper}")

# ê³„ì ˆì„± ì„±ë¶„ í™•ì¸
if prophet_result.seasonal_components:
    for component, values in prophet_result.seasonal_components.items():
        print(f"{component}: {values}")

# ëª¨ë¸ ë©”íŠ¸ë¦­ í™•ì¸
if arima_result.model_metrics:
    for metric, value in arima_result.model_metrics.items():
        print(f"{metric}: {value:.4f}")
```

## ğŸ” ì´ìƒì¹˜ íƒì§€

### AnomalyDetector ì‚¬ìš©ë²•

```python
from bridge.ml.algorithms.anomaly_detection import AnomalyDetector
import numpy as np

# ì´ìƒì¹˜ íƒì§€ê¸° ì´ˆê¸°í™”
detector = AnomalyDetector()

# ë°ì´í„° ì¤€ë¹„
data = np.random.randn(1000)
data[100:110] += 5  # ì´ìƒì¹˜ ì¶”ê°€

# IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
iqr_anomalies = detector.detect_iqr(data, threshold=1.5)
print(f"IQR ì´ìƒì¹˜ ìˆ˜: {len(iqr_anomalies)}")

# Z-score ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
zscore_anomalies = detector.detect_zscore(data, threshold=3.0)
print(f"Z-score ì´ìƒì¹˜ ìˆ˜: {len(zscore_anomalies)}")

# Isolation Forestë¡œ ì´ìƒì¹˜ íƒì§€
isolation_anomalies = detector.detect_isolation_forest(data, contamination=0.1)
print(f"Isolation Forest ì´ìƒì¹˜ ìˆ˜: {len(isolation_anomalies)}")

# One-Class SVMìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
svm_anomalies = detector.detect_one_class_svm(data, nu=0.1)
print(f"One-Class SVM ì´ìƒì¹˜ ìˆ˜: {len(svm_anomalies)}")
```

## ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§

### ClusteringAnalyzer ì‚¬ìš©ë²•

```python
from bridge.ml.algorithms.clustering import ClusteringAnalyzer
import numpy as np

# í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ê¸° ì´ˆê¸°í™”
clustering = ClusteringAnalyzer()

# ë°ì´í„° ì¤€ë¹„
data = np.random.randn(100, 2)

# K-means í´ëŸ¬ìŠ¤í„°ë§
kmeans_clusters = clustering.kmeans(data, n_clusters=3)
print(f"K-means í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(np.unique(kmeans_clusters))}")

# DBSCAN í´ëŸ¬ìŠ¤í„°ë§
dbscan_clusters = clustering.dbscan(data, eps=0.5, min_samples=5)
print(f"DBSCAN í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(np.unique(dbscan_clusters))}")

# ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§
hierarchical_clusters = clustering.hierarchical(data, n_clusters=3)
print(f"ê³„ì¸µì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(np.unique(hierarchical_clusters))}")

# í´ëŸ¬ìŠ¤í„° í‰ê°€
silhouette_score = clustering.evaluate_silhouette(data, kmeans_clusters)
print(f"ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_score:.4f}")
```

## ğŸ“‰ ì°¨ì› ì¶•ì†Œ

### DimensionalityReducer ì‚¬ìš©ë²•

```python
from bridge.ml.algorithms.dimensionality_reduction import DimensionalityReducer
import numpy as np

# ì°¨ì› ì¶•ì†Œê¸° ì´ˆê¸°í™”
reducer = DimensionalityReducer()

# ë°ì´í„° ì¤€ë¹„
data = np.random.randn(100, 10)  # 10ì°¨ì› ë°ì´í„°

# PCA ì°¨ì› ì¶•ì†Œ
pca_data = reducer.pca(data, n_components=2)
print(f"PCA ê²°ê³¼: {pca_data.shape}")

# t-SNE ì°¨ì› ì¶•ì†Œ
tsne_data = reducer.tsne(data, n_components=2)
print(f"t-SNE ê²°ê³¼: {tsne_data.shape}")

# UMAP ì°¨ì› ì¶•ì†Œ
umap_data = reducer.umap(data, n_components=2)
print(f"UMAP ê²°ê³¼: {umap_data.shape}")

# ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨ í™•ì¸
explained_variance = reducer.get_explained_variance_ratio(data, n_components=2)
print(f"ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨: {explained_variance}")
```

## ğŸ¤– ëª¨ë¸ ê´€ë¦¬

### ModelRegistry ì‚¬ìš©ë²•

```python
from bridge.ml.models.registry import ModelRegistry
from bridge.governance.contracts import ModelContract, ModelType, ModelStatus

# ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
registry = ModelRegistry(storage_path="models")

# ëª¨ë¸ ê³„ì•½ ìƒì„±
model_contract = ModelContract(
    id="churn_model_001",
    name="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸",
    model_type=ModelType.CLASSIFICATION,
    version="1.0.0",
    status=ModelStatus.READY,
    metadata={
        "algorithm": "RandomForest",
        "accuracy": 0.85,
        "features": ["age", "income", "usage_days"]
    }
)

# ëª¨ë¸ ë“±ë¡
registry.register_model(model_contract)
print("ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")

# ëª¨ë¸ ì¡°íšŒ
model = registry.get_model("churn_model_001")
print(f"ëª¨ë¸ ì¡°íšŒ: {model.name}")

# ëª¨ë“  ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
models = registry.list_models()
print(f"ë“±ë¡ëœ ëª¨ë¸ ìˆ˜: {len(models)}")

# ëª¨ë¸ ê²€ìƒ‰
search_results = registry.search_models(
    model_type=ModelType.CLASSIFICATION,
    status=ModelStatus.READY
)
print(f"ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
```

### ëª¨ë¸ ì¶”ë¡ 

```python
from bridge.ml.models.inference import ModelInference

# ëª¨ë¸ ì¶”ë¡ ê¸° ì´ˆê¸°í™”
inference = ModelInference(registry)

# ëª¨ë¸ ë¡œë“œ
model = inference.load_model("churn_model_001", version="1.0.0")

# ì˜ˆì¸¡ ìˆ˜í–‰
test_data = [[25, 50000, 30], [35, 75000, 60]]
predictions = inference.predict(
    model_id="churn_model_001",
    data=test_data,
    version="1.0.0"
)
print(f"ì˜ˆì¸¡ ê²°ê³¼: {predictions}")

# ë°°ì¹˜ ì˜ˆì¸¡
batch_predictions = inference.batch_predict(
    model_id="churn_model_001",
    data_list=[test_data, test_data]
)
print(f"ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼: {len(batch_predictions)}ê°œ")
```

## ğŸ“‹ ê±°ë²„ë„ŒìŠ¤ ê³„ì•½

### DataContract ì‚¬ìš©ë²•

```python
from bridge.governance.contracts import DataContract, DataType, QualityRule

# ë°ì´í„° ê³„ì•½ ìƒì„±
contract = DataContract(
    id="customer_data_contract",
    name="ê³ ê° ë°ì´í„° ê³„ì•½",
    version="1.0.0",
    schema={
        "customer_id": DataType.INTEGER,
        "name": DataType.STRING,
        "email": DataType.STRING,
        "age": DataType.INTEGER,
        "created_at": DataType.DATETIME
    },
    quality_rules=[
        QualityRule(
            field="customer_id",
            rule_type="not_null",
            description="ê³ ê° IDëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤"
        ),
        QualityRule(
            field="email",
            rule_type="email_format",
            description="ì´ë©”ì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì•¼ í•©ë‹ˆë‹¤"
        ),
        QualityRule(
            field="age",
            rule_type="range",
            parameters={"min": 0, "max": 120},
            description="ë‚˜ì´ëŠ” 0-120 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤"
        )
    ]
)

# ë°ì´í„° ê²€ì¦
test_data = {
    "customer_id": 1,
    "name": "í™ê¸¸ë™",
    "email": "hong@example.com",
    "age": 30,
    "created_at": "2024-01-01T00:00:00Z"
}

validation_result = contract.validate_data(test_data)
if validation_result.is_valid:
    print("ë°ì´í„°ê°€ ê³„ì•½ì„ ë§Œì¡±í•©ë‹ˆë‹¤")
else:
    print(f"ê²€ì¦ ì‹¤íŒ¨: {validation_result.errors}")
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ë°ì´í„° ì „ì²˜ë¦¬

```python
# ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬
cleaned_data = analyzer.handle_missing_values(data, method='interpolate')
cleaned_data = analyzer.remove_outliers(cleaned_data, method='iqr')
normalized_data = analyzer.normalize(cleaned_data, method='minmax')
differenced_data = analyzer.difference(normalized_data, periods=1)
```

### ëª¨ë¸ í‰ê°€

```python
# êµì°¨ ê²€ì¦
cv_scores = analyzer.cross_validate(data, model_type='arima', cv_folds=5)
print(f"êµì°¨ ê²€ì¦ ì ìˆ˜: {cv_scores}")

# ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€
accuracy = analyzer.evaluate_forecast(actual, predicted)
print(f"ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.4f}")
```

### ì„±ëŠ¥ ìµœì í™”

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
for chunk in analyzer.process_in_chunks(data, chunk_size=1000):
    result = analyzer.fit_arima(chunk)
    # ê²°ê³¼ ì €ì¥

# ë³‘ë ¬ ì²˜ë¦¬
results = analyzer.fit_multiple_models(data, models=['arima', 'prophet', 'lstm'])
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **ë°ì´í„° í’ˆì§ˆ**: ML ë¶„ì„ ì „ì— ë°ì´í„° í’ˆì§ˆì„ ë°˜ë“œì‹œ í™•ì¸
2. **ì •ìƒì„± ê²€ì‚¬**: ARIMA ëª¨ë¸ ì‚¬ìš© ì „ì— ì •ìƒì„± ê²€ì‚¬ í•„ìˆ˜
3. **ê³„ì ˆì„± ê³ ë ¤**: ê³„ì ˆì„±ì´ ìˆëŠ” ë°ì´í„°ëŠ” Prophet ëª¨ë¸ ê¶Œì¥
4. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
5. **ëª¨ë¸ ê²€ì¦**: êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ í•„ìˆ˜
6. **ê³„ì•½ ì¤€ìˆ˜**: ë°ì´í„° ê³„ì•½ì„ í†µí•œ í’ˆì§ˆ ë³´ì¥

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [ì‹œê³„ì—´ ë¶„ì„ ê°€ì´ë“œ](docs/time-series-analysis.md)
- [ëª¨ë¸ ê´€ë¦¬ ê°€ì´ë“œ](docs/model-management.md)
- [ê±°ë²„ë„ŒìŠ¤ ê³„ì•½ ê°€ì´ë“œ](docs/governance-contracts.md)
- [API ì°¸ì¡° ë¬¸ì„œ](docs/api-reference.md)
