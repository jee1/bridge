# 브리지 모델 컨텍스트 프로토콜

## 목적
Bridge는 분석가와 비즈니스 팀이 AI 에이전트를 활용하여 고급 데이터 작업을 수행할 수 있도록 지원합니다. MySQL, PostgreSQL, MongoDB, Databricks, Elasticsearch 등 이기종 데이터베이스 접근을 표준화하고, 대규모 언어 모델이 엔터프라이즈 데이터를 안전하고 투명하게 추론할 수 있도록 일관된 Model Context Protocol(MCP)을 제공합니다.

## 설계 목표
- 데이터를 복제하거나 경직된 ETL 파이프라인을 강제하지 않고 엔터프라이즈 데이터 접근을 통합한다.
- AI 추론을 예측 가능하고 감사 가능한 재사용형 컨텍스트 패키지로 제공한다.
- 통계, 세그먼트 추출, 유사도 분석, 맞춤형 분석을 위한 안내형 워크플로를 제공한다.
- 소스 수준 권한, 마스킹, 가시성을 적용하여 데이터 거버넌스를 보장한다.

## 핵심 개념
### Model Context Protocol(MCP)
AI 모델이 사용자 요청을 해결하기 위해 필요로 하는 컨텍스트를 Bridge가 어떻게 구축, 검증, 전달하는지를 정의하는 명세다. 주요 항목은 다음과 같다.
- 메타데이터, 쿼리 플랜, 샘플 레코드, 가이던스를 묶어 전달하는 컨텍스트 패키지.
- AI 세션 중 어디에서 외부 도구(SQL 엔진, 벡터 스토어, 노트북)를 호출할지 결정하는 실행 훅.
- 사용자 피드백을 수집하여 향후 세션에서 힌트로 재사용하는 피드백 채널.

### 데이터 커넥터
Bridge는 SQL, NoSQL, 분석 엔진용 커넥터를 기본 제공한다. 각 커넥터는 다음을 지원한다.
- 스키마 탐색 및 프로파일링(데이터 타입, 기본 키, 갱신 주기).
- 정책 기반 자격 증명 저장 및 로테이션.
- 필터와 집계를 푸시다운하여 데이터 이그레스 최소화.
- 원본이 임의 탐색을 허용하지 않을 때를 위한 선택적 캐싱 또는 스냅샷.

### AI 오케스트레이터
프롬프트, 도구, 그라운딩 데이터를 조율하는 서비스다. 주요 책임은 다음과 같다.
- 사용자 의도를 구조화된 작업(쿼리, 변환, 요약)으로 변환.
- 최적의 실행 플랜 선정(SQL 직접 실행, Databricks 잡, Elasticsearch 쿼리, Python UDF 등).
- 중간 결과를 병합하고 MCP 컨텍스트로 재패키징.
- 비용, 지연, 품질 지표를 추적하여 지속적으로 개선.

### 워크스페이스와 프로젝트
데이터 소스, 저장 분석, 접근 정책을 그룹화하는 논리적 컨테이너다. 프로젝트는 다음을 포함한다.
- 등록된 커넥터와 해당 스코프(스키마, 인덱스, 카탈로그).
- 저장된 프롬프트, 템플릿, 자동화 스케줄.
- 사용량, 성능, 이상 징후를 모니터링하는 가시화 대시보드.

## 참조 아키텍처
1. 데이터 소스 커넥터가 메타데이터, 통계, 자격 증명을 수집한다.
2. 적재 및 프로파일링 서비스가 시맨틱 카탈로그와 계보 그래프를 갱신한다.
3. 시맨틱 레이어가 비즈니스 정의와 민감도 태그를 포함한 논리 엔터티(테이블, 세그먼트, 피처)를 노출한다.
4. 프롬프트 오케스트레이터가 컨텍스트 패키지를 컴파일하여 MCP를 통해 LLM 또는 기타 AI 런타임으로 전달한다.
5. 도구 실행기가 SQL, Spark, Python, 벡터 유사도 작업을 수행하고 구조화된 결과를 생성한다.
6. 후처리 서비스가 결과를 검증하고 거버넌스 검사를 거친 뒤 요청 채널(챗, API, 노트북, 대시보드)에 응답을 게시한다.

## 엔드 투 엔드 워크플로
1. 안내형 온보딩을 통해 데이터 소스를 연결한다(자격 증명, 동기화 주기, 샘플 정책 설정).
2. 스키마를 자동 프로파일링하고 시맨틱 태그(차원, 측정값, 식별자)를 생성한다.
3. 사용자가 챗 혹은 API를 통해 "지역별 이탈 위험을 비교해줘"와 같은 작업을 설명한다.
4. Bridge가 의도를 MCP 작업으로 매핑하여 컨텍스트 수집, 쿼리 계획, 실행, 요약을 수행한다.
5. SQL, 코드, 벡터 검색 결과 등의 중간 산출물을 검증하고 버전 관리하여 세션에 첨부한다.
6. AI 에이전트가 설명, 시각 요약, 기계 판독 가능한 출력(CSV, JSON, 노트북 셀)을 제공한다.

## AI 작업 템플릿
| 패턴               | 목표                                         | 필수 입력                           | 전형 출력                                |
|--------------------|----------------------------------------------|-------------------------------------|------------------------------------------|
| 기술 통계          | 지표 요약, 추세, 이상 징후 파악              | 테이블 또는 논리 엔터티             | 내러티브 요약과 핵심 지표                |
| 세그먼트 추출      | 규칙 또는 유사도로 코호트를 식별            | 모수 엔터티, 필터 또는 특성         | 세그먼트 정의와 내보내기 핸들            |
| 유사도 비교        | 엔터티 또는 행동 간 유사도 측정              | 피처 벡터, 유사도 지표              | 상위 순위 목록과 설명 토큰               |
| 맞춤형 분석        | 도구를 조합한 다단계 워크플로 구성          | 프롬프트, 선택적 코드 템플릿        | 노트북 셀, 대시보드, API 응답            |

템플릿은 버전 관리되고 파라미터화되어 승인된 로직을 고정하면서도 AI 기반 탐색을 허용한다.

## 거버넌스, 신뢰, 안전성
- 프로젝트, 커넥터, 데이터셋에 대한 역할 기반 접근 제어.
- 민감 컬럼 보호를 위한 쿼리 리라이팅 및 데이터 마스킹.
- 명시적 도구 허용 목록을 갖춘 실행 샌드박스.
- 컴플라이언스를 위한 계보 추적과 변경 불가능한 세션 로그.
- 결과 공유 전 행 데이터 제한, 통계적 신뢰도 검사 등 품질 가드레일.

## 확장 로드맵
- 추가 커넥터(Snowflake, BigQuery, Azure Data Explorer 등).
- 사용 텔레메트리를 활용한 적응형 시맨틱 모델링.
- 데이터 과학자를 위한 자동 노트북 생성.
- 저장된 AI 작업을 활용한 정기 인사이트 및 알림.
- 파트너가 도메인별 템플릿이나 도구를 기여할 수 있는 플러그인 프레임워크.

## MCP 예시 프롬프트
```
사용자 의도: "프리미엄 세그먼트와 유사한 구매 패턴을 보이는 상위 5개 고객 코호트를 찾고, 이들의 이탈 위험을 요약해줘."

MCP 패키징 단계:
1. 시맨틱 카탈로그에서 프리미엄 세그먼트 엔터티를 식별한다.
2. PostgreSQL과 Databricks에서 관련 팩트 테이블과 피처 벡터를 가져온다.
3. 코사인 유사도와 12개월 윈도우를 설정하여 유사도 템플릿을 호출한다.
4. 필요한 쿼리를 필터 푸시다운과 함께 실행하고 집계 지표를 생성한다.
5. 코호트 정의, 유사도 점수, 이탈 지표, 메타데이터를 포함한 컨텍스트를 조립한다.
6. 발견사항과 주의사항을 서술하도록 지침을 추가해 LLM에 컨텍스트를 전달한다.
```

## 다음 단계
- 고객 수요에 기반한 커넥터 백로그 우선순위를 정한다.
- 장시간 분석 작업을 위한 SLA와 모니터링을 정의한다.
- 샘플 프로젝트, 샌드박스 데이터셋, 워크스루 영상을 포함한 온보딩 자산을 준비한다.
