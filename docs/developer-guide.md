# Bridge ê°œë°œì ê°€ì´ë“œ

## ğŸ“– ê°œìš”

ì´ ê°€ì´ë“œëŠ” Bridge í”„ë¡œì íŠ¸ì˜ ê°œë°œ í™˜ê²½ ì„¤ì •, ì½”ë“œ êµ¬ì¡°, ê°œë°œ ì›Œí¬í”Œë¡œìš°, ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ê°œë°œ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- **Python**: 3.11 ì´ìƒ
- **Node.js**: 18 ì´ìƒ (ë¬¸ì„œí™”ìš©)
- **Docker**: 20.10 ì´ìƒ (ì„ íƒì‚¬í•­)
- **Git**: 2.30 ì´ìƒ

### ì´ˆê¸° ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-org/bridge.git
cd bridge

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
make install

# ê°œë°œ ì„œë²„ ì‹¤í–‰
make dev
```

### IDE ì„¤ì •

#### VS Code ì„¤ì •

`.vscode/settings.json`:
```json
{
  "python.defaultInterpreterPath": "./venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": false,
  "python.linting.flake8Enabled": true,
  "python.formatting.provider": "black",
  "python.formatting.blackArgs": ["--line-length", "100"],
  "python.sortImports.args": ["--profile", "black"],
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.organizeImports": true
  }
}
```

#### PyCharm ì„¤ì •

1. **í”„ë¡œì íŠ¸ ì¸í„°í”„ë¦¬í„° ì„¤ì •**:
   - File â†’ Settings â†’ Project â†’ Python Interpreter
   - ê°€ìƒí™˜ê²½ì˜ Python ì¸í„°í”„ë¦¬í„° ì„ íƒ

2. **ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì •**:
   - File â†’ Settings â†’ Editor â†’ Code Style â†’ Python
   - Scheme: Black (ì„¤ì¹˜ í•„ìš”)

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
src/bridge/
â”œâ”€â”€ analytics/                 # ë¶„ì„ ë„êµ¬
â”‚   â”œâ”€â”€ core/                 # í•µì‹¬ ë¶„ì„ ê¸°ëŠ¥
â”‚   â”‚   â”œâ”€â”€ data_integration.py    # ë°ì´í„° í†µí•©
â”‚   â”‚   â”œâ”€â”€ statistics.py          # í†µê³„ ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ quality.py             # í’ˆì§ˆ ê²€ì‚¬
â”‚   â”‚   â””â”€â”€ visualization.py       # ì‹œê°í™”
â”‚   â”œâ”€â”€ utils/                # ë¶„ì„ ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ tests/                # ë¶„ì„ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ connectors/               # ë°ì´í„° ì»¤ë„¥í„°
â”‚   â”œâ”€â”€ base.py              # ê¸°ë³¸ ì»¤ë„¥í„° í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ postgres.py          # PostgreSQL ì»¤ë„¥í„°
â”‚   â”œâ”€â”€ mongodb.py           # MongoDB ì»¤ë„¥í„°
â”‚   â”œâ”€â”€ elasticsearch.py     # Elasticsearch ì»¤ë„¥í„°
â”‚   â””â”€â”€ mock.py              # Mock ì»¤ë„¥í„°
â”œâ”€â”€ orchestrator/            # FastAPI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚   â”œâ”€â”€ app.py               # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ routers.py           # API ë¼ìš°í„°
â”‚   â”œâ”€â”€ tasks.py             # Celery íƒœìŠ¤í¬
â”‚   â””â”€â”€ queries.py           # ì¿¼ë¦¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ governance/              # ë°ì´í„° ê±°ë²„ë„ŒìŠ¤
â”‚   â”œâ”€â”€ contracts.py         # ë°ì´í„° ê³„ì•½
â”‚   â”œâ”€â”€ metadata.py          # ë©”íƒ€ë°ì´í„° ì¹´íƒˆë¡œê·¸
â”‚   â”œâ”€â”€ rbac.py              # RBAC ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ audit.py             # ê°ì‚¬ ë¡œê·¸
â”œâ”€â”€ automation/              # ìë™í™” íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ quality_monitor.py   # í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ report_automation.py # ë¦¬í¬íŠ¸ ìë™í™”
â”‚   â”œâ”€â”€ notification_system.py # ì•Œë¦¼ ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ scheduler.py         # ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
â”œâ”€â”€ dashboard/               # ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ dashboard_manager.py # ëŒ€ì‹œë³´ë“œ ê´€ë¦¬
â”‚   â”œâ”€â”€ monitoring_dashboard.py # ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
â”‚   â”œâ”€â”€ real_time_monitor.py # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
â”‚   â””â”€â”€ visualization_engine.py # ì‹œê°í™” ì—”ì§„
â””â”€â”€ mcp_server_unified.py    # í†µí•© MCP ì„œë²„
```

## ğŸ”§ ê°œë°œ ì›Œí¬í”Œë¡œìš°

### 1. ë¸Œëœì¹˜ ì „ëµ

```bash
# ê¸°ëŠ¥ ê°œë°œ
git checkout -b feature/new-feature

# ë²„ê·¸ ìˆ˜ì •
git checkout -b fix/bug-description

# í•«í”½ìŠ¤
git checkout -b hotfix/critical-fix
```

### 2. ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬

```bash
# ì½”ë“œ í¬ë§·íŒ…
make fmt

# ë¦°í„° ì‹¤í–‰
make lint

# íƒ€ì… ì²´í¬
mypy src/

# ë³´ì•ˆ ê²€ì‚¬
bandit -r src/
```

### 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
make test

# íŠ¹ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
pytest tests/analytics/test_statistics.py -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ í…ŒìŠ¤íŠ¸
make test -- --cov=src --cov-report=html

# í†µí•© í…ŒìŠ¤íŠ¸
docker-compose -f docker-compose.dev.yml run --rm test
```

### 4. ì»¤ë°‹ ë° PR

```bash
# ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§•
git add .

# ì»¤ë°‹ (ì»¨ë²¤ì…˜ ì¤€ìˆ˜)
git commit -m "feat(analytics): add correlation analysis"

# í‘¸ì‹œ
git push origin feature/new-feature

# PR ìƒì„±
gh pr create --title "ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€" --body "ìƒì„¸ ì„¤ëª…"
```

## ğŸ§© ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€

### 1. ìƒˆë¡œìš´ ì»¤ë„¥í„° ì¶”ê°€

```python
# src/bridge/connectors/new_database.py
from typing import Dict, Any, AsyncGenerator
from .base import BaseConnector

class NewDatabaseConnector(BaseConnector):
    """ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥í„°"""
    
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self._connection = None
    
    async def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸ ë¡œì§
            return True
        except Exception as e:
            self.logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    async def get_metadata(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë¡œì§
            return {
                "tables": ["table1", "table2"],
                "version": "1.0"
            }
        except Exception as e:
            self.logger.error(f"ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    async def run_query(self, query: str, params: Dict[str, Any] = None) -> AsyncGenerator[Dict[str, Any], None]:
        """ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            # ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§
            async for row in self._execute_query(query, params):
                yield row
        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    async def _execute_query(self, query: str, params: Dict[str, Any] = None):
        """ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§"""
        # êµ¬í˜„
        pass
```

### 2. ìƒˆë¡œìš´ ë¶„ì„ ë„êµ¬ ì¶”ê°€

```python
# src/bridge/analytics/core/new_analyzer.py
from typing import Dict, Any, List
from ..data_integration import UnifiedDataFrame

class NewAnalyzer:
    """ìƒˆë¡œìš´ ë¶„ì„ ë„êµ¬"""
    
    def __init__(self):
        self.name = "New Analyzer"
        self.version = "1.0"
    
    def analyze(self, data: UnifiedDataFrame, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """ë¶„ì„ ìˆ˜í–‰"""
        try:
            pandas_df = data.to_pandas()
            
            # ë¶„ì„ ë¡œì§ êµ¬í˜„
            result = self._perform_analysis(pandas_df, config)
            
            return {
                "status": "success",
                "result": result,
                "metadata": {
                    "analyzer": self.name,
                    "version": self.version,
                    "data_shape": pandas_df.shape
                }
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def _perform_analysis(self, df, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‹¤ì œ ë¶„ì„ ë¡œì§"""
        # êµ¬í˜„
        pass
```

### 3. ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
# src/bridge/orchestrator/routers.py
from fastapi import APIRouter, HTTPException, Depends
from ..semantic.models import TaskRequest, TaskResponse
from ..auth import get_current_user

router = APIRouter()

@router.post("/new-endpoint", response_model=TaskResponse)
async def new_endpoint(
    request: TaskRequest,
    current_user: dict = Depends(get_current_user)
) -> TaskResponse:
    """ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ êµ¬í˜„
        result = await process_new_request(request)
        
        return TaskResponse(
            status="success",
            data=result,
            message="ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

async def process_new_request(request: TaskRequest) -> Dict[str, Any]:
    """ìƒˆë¡œìš´ ìš”ì²­ ì²˜ë¦¬ ë¡œì§"""
    # êµ¬í˜„
    pass
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì„±

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/analytics/test_new_analyzer.py
import pytest
from src.bridge.analytics.core.new_analyzer import NewAnalyzer
from src.bridge.analytics.core.data_integration import UnifiedDataFrame
import pandas as pd

class TestNewAnalyzer:
    """NewAnalyzer í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def setup_method(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.analyzer = NewAnalyzer()
        self.sample_data = pd.DataFrame({
            'value1': [1, 2, 3, 4, 5],
            'value2': [10, 20, 30, 40, 50]
        })
        self.unified_df = UnifiedDataFrame(self.sample_data)
    
    def test_analyze_success(self):
        """ì„±ê³µì ì¸ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        result = self.analyzer.analyze(self.unified_df)
        
        assert result["status"] == "success"
        assert "result" in result
        assert "metadata" in result
    
    def test_analyze_with_config(self):
        """ì„¤ì •ì´ ìˆëŠ” ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        config = {"param1": "value1"}
        result = self.analyzer.analyze(self.unified_df, config)
        
        assert result["status"] == "success"
    
    def test_analyze_error_handling(self):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ì˜ëª»ëœ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        invalid_data = UnifiedDataFrame(pd.DataFrame())
        result = self.analyzer.analyze(invalid_data)
        
        assert result["status"] == "error"
        assert "error" in result
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_new_feature_integration.py
import pytest
from fastapi.testclient import TestClient
from src.bridge.orchestrator.app import app

client = TestClient(app)

class TestNewFeatureIntegration:
    """ìƒˆë¡œìš´ ê¸°ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def test_new_endpoint_success(self):
        """ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/api/v1/new-endpoint",
            json={
                "intent": "í…ŒìŠ¤íŠ¸ ìš”ì²­",
                "sources": ["mock://test"],
                "required_tools": ["new_analyzer"]
            },
            headers={"Authorization": "Bearer test_token"}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "success"
    
    def test_new_endpoint_validation_error(self):
        """ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦ ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/api/v1/new-endpoint",
            json={},  # ì˜ëª»ëœ ìš”ì²­
            headers={"Authorization": "Bearer test_token"}
        )
        
        assert response.status_code == 422
    
    def test_new_endpoint_authentication_error(self):
        """ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ì¸ì¦ ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸"""
        response = client.post(
            "/api/v1/new-endpoint",
            json={
                "intent": "í…ŒìŠ¤íŠ¸ ìš”ì²­",
                "sources": ["mock://test"]
            }
            # ì¸ì¦ í—¤ë” ì—†ìŒ
        )
        
        assert response.status_code == 401
```

### 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```python
# tests/performance/test_new_feature_performance.py
import pytest
import time
from src.bridge.analytics.core.new_analyzer import NewAnalyzer
from src.bridge.analytics.core.data_integration import UnifiedDataFrame
import pandas as pd

class TestNewFeaturePerformance:
    """ìƒˆë¡œìš´ ê¸°ëŠ¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def test_analyzer_performance(self):
        """ë¶„ì„ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        analyzer = NewAnalyzer()
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±
        large_data = pd.DataFrame({
            'value1': range(10000),
            'value2': range(10000, 20000)
        })
        unified_df = UnifiedDataFrame(large_data)
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        result = analyzer.analyze(unified_df)
        end_time = time.time()
        
        execution_time = end_time - start_time
        
        # ì„±ëŠ¥ ê²€ì¦ (1ì´ˆ ì´ë‚´)
        assert execution_time < 1.0
        assert result["status"] == "success"
    
    def test_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
        analyzer = NewAnalyzer()
        large_data = pd.DataFrame({
            'value1': range(100000),
            'value2': range(100000, 200000)
        })
        unified_df = UnifiedDataFrame(large_data)
        
        result = analyzer.analyze(unified_df)
        
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ ê²€ì¦ (100MB ì´ë‚´)
        assert memory_increase < 100 * 1024 * 1024
```

## ğŸ” ë””ë²„ê¹…

### 1. ë¡œê·¸ ì„¤ì •

```python
# src/bridge/logging_config.py
import logging
import sys
from pathlib import Path

def setup_logging(level: str = "INFO"):
    """ë¡œê¹… ì„¤ì •"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger("bridge")
    logger.setLevel(getattr(logging, level.upper()))
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler(log_dir / "bridge.log")
    file_handler.setLevel(logging.INFO)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.DEBUG)
    
    # í¬ë§·í„°
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger
```

### 2. ë””ë²„ê¹… ë„êµ¬

```python
# ë””ë²„ê¹…ìš© ì½”ë“œ
import logging
from src.bridge.logging_config import setup_logging

# ë¡œê¹… ì„¤ì •
logger = setup_logging("DEBUG")

def debug_function():
    """ë””ë²„ê¹… í•¨ìˆ˜"""
    logger.debug("í•¨ìˆ˜ ì‹œì‘")
    
    try:
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
        result = process_data()
        logger.debug(f"ì²˜ë¦¬ ê²°ê³¼: {result}")
        
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise
    
    logger.debug("í•¨ìˆ˜ ì™„ë£Œ")
    return result
```

### 3. í”„ë¡œíŒŒì¼ë§

```python
# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
import cProfile
import pstats
from io import StringIO

def profile_function(func, *args, **kwargs):
    """í•¨ìˆ˜ í”„ë¡œíŒŒì¼ë§"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    result = func(*args, **kwargs)
    
    profiler.disable()
    
    # ê²°ê³¼ ì¶œë ¥
    s = StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
    ps.print_stats()
    
    print(s.getvalue())
    return result

# ì‚¬ìš© ì˜ˆì‹œ
result = profile_function(analyzer.analyze, unified_df)
```

## ğŸ“š ë¬¸ì„œí™”

### 1. ì½”ë“œ ë¬¸ì„œí™”

```python
def analyze_data(data: UnifiedDataFrame, config: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        data: ë¶„ì„í•  ë°ì´í„° (UnifiedDataFrame)
        config: ë¶„ì„ ì„¤ì • (ì„ íƒì‚¬í•­)
            - param1: ì²« ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜
            - param2: ë‘ ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            - status: ë¶„ì„ ìƒíƒœ ("success" ë˜ëŠ” "error")
            - result: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            - metadata: ë©”íƒ€ë°ì´í„°
    
    Raises:
        ValueError: ì˜ëª»ëœ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš°
        RuntimeError: ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    
    Example:
        >>> data = UnifiedDataFrame(pd.DataFrame({'value': [1, 2, 3]}))
        >>> result = analyze_data(data)
        >>> print(result['status'])
        'success'
    """
    # êµ¬í˜„
    pass
```

### 2. API ë¬¸ì„œí™”

```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

class AnalysisRequest(BaseModel):
    """ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    data_source: str = Field(..., description="ë°ì´í„° ì†ŒìŠ¤ URI")
    table_name: str = Field(..., description="í…Œì´ë¸”ëª…")
    columns: List[str] = Field(..., description="ë¶„ì„í•  ì»¬ëŸ¼ ëª©ë¡")
    config: Dict[str, Any] = Field(default={}, description="ë¶„ì„ ì„¤ì •")

class AnalysisResponse(BaseModel):
    """ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    status: str = Field(..., description="ë¶„ì„ ìƒíƒœ")
    result: Dict[str, Any] = Field(..., description="ë¶„ì„ ê²°ê³¼")
    metadata: Dict[str, Any] = Field(..., description="ë©”íƒ€ë°ì´í„°")

@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_data_endpoint(
    request: AnalysisRequest,
    current_user: dict = Depends(get_current_user)
) -> AnalysisResponse:
    """
    ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    - **data_source**: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ìì—´
    - **table_name**: ë¶„ì„í•  í…Œì´ë¸”ëª…
    - **columns**: ë¶„ì„í•  ì»¬ëŸ¼ ëª©ë¡
    - **config**: ë¶„ì„ ì„¤ì • (ì„ íƒì‚¬í•­)
    
    Returns:
        AnalysisResponse: ë¶„ì„ ê²°ê³¼
    """
    # êµ¬í˜„
    pass
```

## ğŸš€ ë°°í¬

### 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY pyproject.toml .
RUN pip install -e .

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY src/ ./src/
COPY scripts/ ./scripts/

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì‹¤í–‰ ëª…ë ¹
CMD ["python", "-m", "src.bridge.orchestrator.app"]
```

### 2. Docker Compose ì„¤ì •

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  bridge-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - BRIDGE_DATABASE_URL=postgresql://user:pass@db:5432/bridge
      - BRIDGE_REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=bridge
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

### 3. Kubernetes ë°°í¬

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bridge-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bridge-api
  template:
    metadata:
      labels:
        app: bridge-api
    spec:
      containers:
      - name: bridge-api
        image: bridge:latest
        ports:
        - containerPort: 8000
        env:
        - name: BRIDGE_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: bridge-secrets
              key: database-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
```

## ğŸ”§ ìœ ì§€ë³´ìˆ˜

### 1. ì˜ì¡´ì„± ì—…ë°ì´íŠ¸

```bash
# ì˜ì¡´ì„± í™•ì¸
pip list --outdated

# íŠ¹ì • íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
pip install --upgrade package_name

# requirements.txt ì—…ë°ì´íŠ¸
pip freeze > requirements.txt
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

```python
# migrations/001_add_new_table.py
from sqlalchemy import create_engine, text

def upgrade(engine):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì—…ê·¸ë ˆì´ë“œ"""
    with engine.connect() as conn:
        conn.execute(text("""
            CREATE TABLE new_table (
                id SERIAL PRIMARY KEY,
                name VARCHAR(255) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """))
        conn.commit()

def downgrade(engine):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¤ìš´ê·¸ë ˆì´ë“œ"""
    with engine.connect() as conn:
        conn.execute(text("DROP TABLE new_table"))
        conn.commit()
```

### 3. ëª¨ë‹ˆí„°ë§ ì„¤ì •

```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter('bridge_requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('bridge_request_duration_seconds', 'Request duration')
ACTIVE_CONNECTIONS = Gauge('bridge_active_connections', 'Active connections')

def track_request(func):
    """ìš”ì²­ ì¶”ì  ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            REQUEST_COUNT.labels(method='GET', endpoint=func.__name__).inc()
            return result
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    
    return wrapper
```

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

### 1. ì½”ë“œ ë¦¬ë·° ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì½”ë“œê°€ PEP 8 ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ë”°ë¥´ëŠ”ê°€?
- [ ] íƒ€ì… íŒíŠ¸ê°€ ì ì ˆíˆ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì‘ì„±ë˜ì—ˆëŠ”ê°€?
- [ ] ë¬¸ì„œí™”ê°€ ì¶©ë¶„í•œê°€?
- [ ] ì—ëŸ¬ ì²˜ë¦¬ê°€ ì ì ˆí•œê°€?
- [ ] ì„±ëŠ¥ì— ë¬¸ì œê°€ ì—†ëŠ”ê°€?

### 2. PR í…œí”Œë¦¿

```markdown
## ë³€ê²½ì‚¬í•­
- [ ] ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
- [ ] ë²„ê·¸ ìˆ˜ì •
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸
- [ ] í…ŒìŠ¤íŠ¸ ì¶”ê°€

## ì„¤ëª…
ë³€ê²½ì‚¬í•­ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…

## í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

## ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì½”ë“œ ìŠ¤íƒ€ì¼ ì¤€ìˆ˜
- [ ] íƒ€ì… íŒíŠ¸ í¬í•¨
- [ ] ë¬¸ì„œí™” ì™„ë£Œ
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ìœ ì§€
```

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ê°œë°œí•˜ë©´ Bridge í”„ë¡œì íŠ¸ì— íš¨ê³¼ì ìœ¼ë¡œ ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë¬¸ì˜í•˜ì„¸ìš”!
