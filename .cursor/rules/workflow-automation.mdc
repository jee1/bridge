---
description: 워크플로 및 자동화 시스템 관련 규칙
globs: src/bridge/analytics/workflows/*.py,src/bridge/analytics/mcp_tools/workflow_automation_tools.py
---

# 워크플로 및 자동화 시스템 가이드라인

## CA 마일스톤 3.4: 워크플로 및 자동화 시스템

### AnalysisTemplateManager 사용법
```python
from bridge.analytics.workflows.analysis_templates import AnalysisTemplateManager, AnalysisResult
from bridge.analytics.core.data_integration import UnifiedDataFrame

# 분석 템플릿 관리자 초기화
template_manager = AnalysisTemplateManager()

# 사용 가능한 템플릿 목록 조회
templates = template_manager.list_templates()
print(f"사용 가능한 템플릿: {[t['name'] for t in templates]}")

# 템플릿 정보 조회
template_info = template_manager.get_template_info("customer_analysis")
print(f"템플릿 설명: {template_info['template_info']['description']}")

# 템플릿용 데이터 검증
validation_result = template_manager.validate_data_for_template(
    "customer_analysis", unified_data
)
print(f"데이터 검증 결과: {validation_result['is_valid']}")

# 분석 템플릿 실행
analysis_result = template_manager.execute_template(
    template_name="customer_analysis",
    data=unified_data,
    parameters={
        "segmentation_method": "rfm",
        "clusters": 5,
        "time_period": "12M"
    }
)
```

### 고객 분석 템플릿 사용법
```python
from bridge.analytics.workflows.analysis_templates import CustomerAnalysisTemplate

# 고객 분석 템플릿 초기화
customer_template = CustomerAnalysisTemplate()

# 템플릿 정보 확인
template_info = customer_template.get_template_info()
print(f"필수 컬럼: {template_info.required_columns}")

# 데이터 검증
is_valid = customer_template.validate_data(unified_data)

# 고객 분석 실행
if is_valid:
    result = customer_template.execute_analysis(
        data=unified_data,
        parameters={
            "segmentation_method": "rfm",
            "clusters": 5,
            "time_period": "12M"
        }
    )
    
    # 분석 결과 확인
    print(f"분석 성공: {result.success}")
    print(f"RFM 분석 결과: {result.results['rfm_analysis']}")
    print(f"세그멘테이션 결과: {result.results['segmentation']}")
    print(f"권장사항: {result.recommendations}")
```

### 매출 분석 템플릿 사용법
```python
from bridge.analytics.workflows.analysis_templates import SalesAnalysisTemplate

# 매출 분석 템플릿 초기화
sales_template = SalesAnalysisTemplate()

# 매출 분석 실행
result = sales_template.execute_analysis(
    data=unified_data,
    parameters={
        "time_period": "12M",
        "trend_analysis": True,
        "seasonality_analysis": True
    }
)

# 매출 분석 결과 확인
print(f"트렌드 분석: {result.results['trend_analysis']}")
print(f"계절성 분석: {result.results['seasonality_analysis']}")
print(f"카테고리별 분석: {result.results['category_analysis']}")
```

### A/B 테스트 분석 템플릿 사용법
```python
from bridge.analytics.workflows.analysis_templates import ABTestAnalysisTemplate

# A/B 테스트 분석 템플릿 초기화
ab_test_template = ABTestAnalysisTemplate()

# A/B 테스트 분석 실행
result = ab_test_template.execute_analysis(
    data=unified_data,
    parameters={
        "test_type": "conversion",
        "confidence_level": 0.95,
        "minimum_effect_size": 0.05
    }
)

# A/B 테스트 결과 확인
print(f"기본 통계: {result.results['basic_statistics']}")
print(f"유의성 검정: {result.results['significance_test']}")
print(f"효과 크기: {result.results['effect_size']}")
```

### WorkflowAutomationTools 사용법
```python
from bridge.analytics.mcp_tools.workflow_automation_tools import WorkflowAutomationTools

# 워크플로 자동화 도구 초기화
workflow_tools = WorkflowAutomationTools()

# 분석 템플릿 실행
result = workflow_tools.execute_analysis_template(
    template_name="customer_analysis",
    data=unified_data,
    parameters={"segmentation_method": "rfm"}
)

# 워크플로 DAG 생성
workflow_steps = [
    {
        "id": "step1",
        "name": "데이터 로드",
        "type": "data_loading",
        "template": None,
        "parameters": {},
        "dependencies": []
    },
    {
        "id": "step2",
        "name": "고객 분석",
        "type": "analysis",
        "template": "customer_analysis",
        "parameters": {"segmentation_method": "rfm"},
        "dependencies": ["step1"]
    },
    {
        "id": "step3",
        "name": "시각화",
        "type": "visualization",
        "template": None,
        "parameters": {},
        "dependencies": ["step2"]
    }
]

dag_result = workflow_tools.create_workflow_dag(workflow_steps)
print(f"DAG 생성 성공: {dag_result['success']}")
print(f"실행 순서: {dag_result['dag']['execution_order']}")

# 워크플로 성능 최적화
optimization_result = workflow_tools.optimize_workflow_performance({
    "steps": workflow_steps
})
print(f"최적화 제안: {optimization_result['optimizations']}")
```

## MCP 도구 사용법

### execute_analysis_template MCP 도구
```json
{
  "tool": "execute_analysis_template",
  "arguments": {
    "template_name": "customer_analysis",
    "data": {...},
    "parameters": {
      "segmentation_method": "rfm",
      "clusters": 5,
      "time_period": "12M"
    }
  }
}
```

### list_analysis_templates MCP 도구
```json
{
  "tool": "list_analysis_templates",
  "arguments": {}
}
```

### get_template_info MCP 도구
```json
{
  "tool": "get_template_info",
  "arguments": {
    "template_name": "customer_analysis"
  }
}
```

### validate_data_for_template MCP 도구
```json
{
  "tool": "validate_data_for_template",
  "arguments": {
    "template_name": "customer_analysis",
    "data": {...}
  }
}
```

### create_workflow_dag MCP 도구
```json
{
  "tool": "create_workflow_dag",
  "arguments": {
    "workflow_steps": [
      {
        "id": "step1",
        "name": "데이터 로드",
        "type": "data_loading",
        "dependencies": []
      },
      {
        "id": "step2",
        "name": "분석 실행",
        "type": "analysis",
        "template": "customer_analysis",
        "dependencies": ["step1"]
      }
    ]
  }
}
```

### optimize_workflow_performance MCP 도구
```json
{
  "tool": "optimize_workflow_performance",
  "arguments": {
    "workflow_config": {
      "steps": [...]
    }
  }
}
```

## 워크플로 패턴

### 1. 고객 분석 워크플로우
```python
# 1단계: 데이터 검증
validation = workflow_tools.validate_data_for_template("customer_analysis", data)

# 2단계: 고객 분석 실행
if validation['is_valid']:
    analysis_result = workflow_tools.execute_analysis_template(
        "customer_analysis", data, {"segmentation_method": "rfm"}
    )
    
    # 3단계: 결과 시각화
    if analysis_result['success']:
        visualizations = analysis_result['visualizations']
        for viz in visualizations:
            print(f"차트: {viz['title']}")
```

### 2. 매출 분석 워크플로우
```python
# 1단계: 매출 분석 실행
sales_result = workflow_tools.execute_analysis_template(
    "sales_analysis", data, {
        "time_period": "12M",
        "trend_analysis": True,
        "seasonality_analysis": True
    }
)

# 2단계: 트렌드 확인
if sales_result['success']:
    trend_data = sales_result['results']['trend_analysis']
    if trend_data['trend_direction'] == '상승':
        print("매출이 상승하고 있습니다")
    elif trend_data['trend_direction'] == '하락':
        print("매출이 하락하고 있습니다")
```

### 3. A/B 테스트 워크플로우
```python
# 1단계: A/B 테스트 실행
ab_result = workflow_tools.execute_analysis_template(
    "ab_test_analysis", data, {
        "test_type": "conversion",
        "confidence_level": 0.95
    }
)

# 2단계: 결과 해석
if ab_result['success']:
    significance = ab_result['results']['significance_test']
    if significance['is_significant']:
        print("통계적으로 유의한 차이가 있습니다")
    else:
        print("통계적으로 유의한 차이가 없습니다")
```

## 성능 최적화

### 병렬 템플릿 실행
```python
from concurrent.futures import ThreadPoolExecutor

def run_multiple_analyses(data, template_configs):
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for config in template_configs:
            future = executor.submit(
                workflow_tools.execute_analysis_template,
                config['template_name'], data, config['parameters']
            )
            futures.append(future)
        
        results = [future.result() for future in futures]
    return results
```

### 워크플로 캐싱
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_template_execution(template_name, data_hash, params_hash):
    return workflow_tools.execute_analysis_template(
        template_name, data, parameters
    )
```

## 에러 처리

### 템플릿 실행 에러 처리
```python
try:
    result = workflow_tools.execute_analysis_template(
        template_name, data, parameters
    )
except TemplateExecutionError as e:
    logger.error(f"템플릿 실행 실패: {e}")
    # 기본 분석으로 대체
    result = workflow_tools.execute_analysis_template(
        "basic_analysis", data, {}
    )
```

### 워크플로 DAG 에러 처리
```python
try:
    dag_result = workflow_tools.create_workflow_dag(workflow_steps)
except DAGCreationError as e:
    logger.error(f"DAG 생성 실패: {e}")
    # 단순 순차 실행으로 대체
    dag_result = {
        "success": True,
        "execution_order": [step["id"] for step in workflow_steps]
    }
```

## 주의사항

1. **템플릿 검증**: 실행 전에 데이터가 템플릿 요구사항을 만족하는지 확인
2. **워크플로 의존성**: DAG에서 순환 의존성 방지
3. **성능 모니터링**: 대용량 데이터 처리 시 실행 시간 모니터링
4. **에러 복구**: 부분 실패 시 대체 전략 준비
5. **결과 검증**: 분석 결과의 신뢰성 확인
6. **템플릿 확장**: 새로운 분석 템플릿 추가 시 일관성 유지